<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Kylin&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Write.Rewrite.When not writing or rewriting, read.I know of no shortcuts.">
<meta property="og:type" content="website">
<meta property="og:title" content="Kylin's Blog">
<meta property="og:url" content="http://kylin27.github.io/index.html">
<meta property="og:site_name" content="Kylin's Blog">
<meta property="og:description" content="Write.Rewrite.When not writing or rewriting, read.I know of no shortcuts.">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kylin's Blog">
<meta name="twitter:description" content="Write.Rewrite.When not writing or rewriting, read.I know of no shortcuts.">
  
    <link rel="alternative" href="/atom.xml" title="Kylin&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Kylin&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Kylin27@outlook.com</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://kylin27.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2016.2.26.remote_debug_spark_intellij" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/26/2016.2.26.remote_debug_spark_intellij/" class="article-date">
  <time datetime="2016-02-25T16:00:00.000Z" itemprop="datePublished">2016-02-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/26/2016.2.26.remote_debug_spark_intellij/">基于单节点的 Spark &amp; IDEA 远程调试</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:<br>本篇博文主要介绍一下，如何使用 intellij IDEA 这款可视化集成编程工具来远程调试运行在 Spark 集群上面的 jar 文件。<br>在这里采用伪分布式单节点来部署 Spark 的运行环境，目的是为了防止分布式集群环境中(创建多个虚拟机在每台虚拟机上面部署 Spark 环境)一些不可控错误的发生。</p>
<hr>
<h1 id="u73AF_u5883_u642D_u5EFA"><a href="#u73AF_u5883_u642D_u5EFA" class="headerlink" title="环境搭建"></a>环境搭建</h1><h2 id="u5B9E_u9A8C_u73AF_u5883_u51C6_u5907"><a href="#u5B9E_u9A8C_u73AF_u5883_u51C6_u5907" class="headerlink" title="实验环境准备"></a>实验环境准备</h2><ul>
<li>虚拟机 Oracle Virtual Box 版本：5.0.10</li>
<li>虚拟机中的 Linux 版本： 15.0.4</li>
<li>Linux 中安装的 spark 版本: <a href="http://pan.baidu.com/s/1o6P3TVk" target="_blank" rel="external">spark-1.5.2-bin-hadoop2.6.tgz</a></li>
<li>Linux 中安装的 hadoop 版本: <a href="http://pan.baidu.com/s/1o6P3TVk" target="_blank" rel="external">hadoop-2.6.3.tar.gz</a></li>
<li>Linux 中安装的 JDK 版本: 1.7.0</li>
<li>Linux 中安装的 scala 版本: 2.11.7</li>
<li>主机参数: <ul>
<li>CPU: i5-4460  </li>
<li>RAM: 8.00 GB</li>
</ul>
</li>
<li>主机 Intellij 版本: Intellij-14.14 (正版破解版… =。=) </li>
<li>主机 JDK 版本: 1.8.0 </li>
<li>主机 spark 软件发布包:<a href="http://pan.baidu.com/s/1o6P3TVk" target="_blank" rel="external">spark-1.5.2-bin-hadoop2.6.tgz</a></li>
<li><h2 id="u5728_u865A_u62DF_u673A_u4E0A_u90E8_u7F72_u73AF_u5883"><a href="#u5728_u865A_u62DF_u673A_u4E0A_u90E8_u7F72_u73AF_u5883" class="headerlink" title="在虚拟机上部署环境"></a>在虚拟机上部署环境</h2></li>
<li>首先更新 Ubuntu 的源，然后安装 Oracle 版本的 java7 </li>
<li>安装过 spark 的同学告诉我，说是用 java8 来安装 spark 会抛出莫名异常，所以在 Linux 的上用的是就是 java7 版本，而在主机上 Intellij 的编译器使用的是 java8</li>
</ul>
<h3 id="u5355_u70B9_u90E8_u7F72_u5B89_u88C5_hadoop"><a href="#u5355_u70B9_u90E8_u7F72_u5B89_u88C5_hadoop" class="headerlink" title="单点部署安装 hadoop"></a>单点部署安装 hadoop</h3><ul>
<li>将 hadoop 压缩包解压到指定目录下面</li>
</ul>
<pre><code>
$ tar -xzf hadoop-2.6.3.tar.gz 
$ mkdir /hadoop
$ mv hadoop-2.6.3 /hadoop/
</code></pre>

<ul>
<li>为当前结点配置 ssh 的密钥对(即便是单点部署也需要实现 ssh 无密码登陆)</li>
</ul>
<pre><code>
$ apt-get install openssh-server            # 如果系统中没有安装 ssh 软件的话使用 apt-get install 命令安装
$ apt-get install openssh-client        # 安装 ssh 的客户端
$ ssh-keygen -t rsa -P ""                 # 生成无密码的公私密钥对    
$ cd ~/.ssh/                            # 生成的密钥对文件存放在 ~/.ssh/ 文件夹的下面
$ cat id_rsa.pub >> authorized_keys     # 将刚刚生成的公钥文件中的内容以追加的方式写入到 authorized_keys 文件中
$ chmod 600 authorized_keys             # 修改存放公钥文件的权限
$ ssh localhost                            # 使用 ssh 来远程登录自身所在的主机
$ hostname                               # 查看主机名称，我的是 aimer-v，存放主机名的配置文件(Ubuntu)是 /etc/hostname
$ ssh aimer-v                             # 使用 ssh 登录名为 aimer-v 的主机，如果能够成功登录说明 ssh 正常工作，

* 如果出现无法 ssh 正常访问登录的情况的话，首先使用 ping 命令来检查数据包是否可以正常收发
* 如果 ping 没有问题的话同时修改 ssh 对应路径下面的配置文件，并通过重启 ssh 服务来是配置文件生效
* 我的 ssh 配置文件所在路径是

$ /etc/ssh/ssh_config

* 修改过(注销注释)的字段是
   PasswordAuthentication yes
   CheckHostIP yes
   IdentityFile ~/.ssh/id_rsa
   Port 22
   SendEnv LANG LC_*
   HashKnownHosts yes
   GSSAPIAuthentication yes
   GSSAPIDelegateCredentials no

</code></pre>

<ul>
<li>修改系统环境配置文件将 Hadoop 相关路径写入存放到其中,也就是将 Hadoop 安装包所在的文件夹路径添加到系统的搜索路径中，<br>以便于用户无论在那个路径下面输入 Hadoop 相关命令都可以启动运行 Hadoop 文件夹下面的可执行脚本</li>
</ul>
<pre><code>
$　vi /etc/profile            
 在文件的末尾追加

#set for hadoop
export HADOOP_HOME=/hadoop
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
export HADOOP_MAPRED_HOME=$HADOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_HOME/lib/native"

$ source /etc/profile       # 让修改过的系统变量立即生效
</code></pre>

<ul>
<li>修改 Hadoop 的相关配置文件<br>Hadoop 的一系列配置文件所在路径为 ${HADOOP_HOME}/etc/hadoop/ 的下面 </li>
</ul>
<ul>
<li>首先修改的是名为 hadoop-env.sh 的配置文件</li>
</ul>
<pre><code>
  # hadoop-env.sh 文件中记录的是 hadoop 在启动的时候，到哪里去找 java 的编译器
  # 和启动时内存空间大小的分配等，我只修改了下面这一个选项 
  export JAVA_HOME=/usr/lib/jvm/java-7-oracle    
</code></pre>  

<ul>
<li>然后修改的是名为 core-site.xml 的配置文件</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-core-xml.png" alt=""></p>
<ul>
<li>接下来修改的是 hdfs-site.xml </li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-hdfs-xml.png" alt=""> </p>
<ul>
<li>最后修改的是 yarn-site.xml<br>yarn 是 apache 的资源管理调度框架，和 yarn 等价的还有 mesos ，我没有在这里做过深入研究，感兴趣的同学可以进一步查阅相关资料。</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-yarn-xml.png" alt=""></p>
<ul>
<li>根据配置文件中设置的文件夹和文件，并在当前系统中的对应路径下创建对应的文件夹和文件</li>
</ul>
<pre><code>
$ mkdir /hadoop/tmp
$ mkdir /hadoop/dfs
$ mkdir /hadoop/dfs/name
$ mkdir /hadoop/dfs/data
</code></pre>

<ul>
<li>格式化 hdfs </li>
</ul>
<pre><code>
// 首先将路径切换到 ${HADOOP_HOME}/bin 的下面，然后执行下面的命令
$ ./hdfs namenode -format                  # 将 namenode 进行格式化操作

//  如果配置信息无误且正确运行的话，将会显示如下的输出信息 


STARTUP_MSG:   java = 1.7.0_80
************************************************************/
16/02/26 14:33:49 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
16/02/26 14:33:49 INFO namenode.NameNode: createNameNode [-format]
Formatting using clusterid: CID-88b14724-7d23-46fd-a623-83029ad20c44
16/02/26 14:33:51 INFO namenode.FSNamesystem: No KeyProvider found.
16/02/26 14:33:51 INFO namenode.FSNamesystem: fsLock is fair:true
16/02/26 14:33:51 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
16/02/26 14:33:51 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
16/02/26 14:33:51 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
16/02/26 14:33:51 INFO blockmanagement.BlockManager: The block deletion will start around 2016 Feb 26 14:33:51
16/02/26 14:33:51 INFO util.GSet: Computing capacity for map BlocksMap
16/02/26 14:33:51 INFO util.GSet: VM type       = 64-bit
16/02/26 14:33:51 INFO util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
16/02/26 14:33:51 INFO util.GSet: capacity      = 2^21 = 2097152 entries
16/02/26 14:33:51 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
16/02/26 14:33:51 INFO blockmanagement.BlockManager: defaultReplication         = 1
16/02/26 14:33:51 INFO blockmanagement.BlockManager: maxReplication             = 512
16/02/26 14:33:51 INFO blockmanagement.BlockManager: minReplication             = 1
16/02/26 14:33:51 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
16/02/26 14:33:51 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
16/02/26 14:33:51 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
16/02/26 14:33:51 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
16/02/26 14:33:51 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
16/02/26 14:33:51 INFO namenode.FSNamesystem: supergroup          = supergroup
16/02/26 14:33:51 INFO namenode.FSNamesystem: isPermissionEnabled = false
16/02/26 14:33:51 INFO namenode.FSNamesystem: HA Enabled: false
16/02/26 14:33:51 INFO namenode.FSNamesystem: Append Enabled: true
16/02/26 14:33:52 INFO util.GSet: Computing capacity for map INodeMap
16/02/26 14:33:52 INFO util.GSet: VM type       = 64-bit
16/02/26 14:33:52 INFO util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
16/02/26 14:33:52 INFO util.GSet: capacity      = 2^20 = 1048576 entries
16/02/26 14:33:52 INFO namenode.NameNode: Caching file names occuring more than 10 times
16/02/26 14:33:52 INFO util.GSet: Computing capacity for map cachedBlocks
16/02/26 14:33:52 INFO util.GSet: VM type       = 64-bit
16/02/26 14:33:52 INFO util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
16/02/26 14:33:52 INFO util.GSet: capacity      = 2^18 = 262144 entries
16/02/26 14:33:52 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
16/02/26 14:33:52 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
16/02/26 14:33:52 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
16/02/26 14:33:52 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
16/02/26 14:33:52 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
16/02/26 14:33:52 INFO util.GSet: Computing capacity for map NameNodeRetryCache
16/02/26 14:33:52 INFO util.GSet: VM type       = 64-bit
16/02/26 14:33:52 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
16/02/26 14:33:52 INFO util.GSet: capacity      = 2^15 = 32768 entries
16/02/26 14:33:52 INFO namenode.NNConf: ACLs enabled? false
16/02/26 14:33:52 INFO namenode.NNConf: XAttrs enabled? true
16/02/26 14:33:52 INFO namenode.NNConf: Maximum size of an xattr: 16384
Re-format filesystem in Storage Directory /hadoop/dfs/name ? (Y or N) 

//  输入 'Y' 表示同意格式化 namenode 
//  如果成功初始化的话，将会显示如下的信息 

16/02/26 14:34:55 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1525144641-127.0.0.1-1456468495698
16/02/26 14:34:56 INFO common.Storage: Storage directory /hadoop/dfs/name has been successfully formatted.
16/02/26 14:34:56 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
16/02/26 14:34:56 INFO util.ExitUtil: Exiting with status 0
16/02/26 14:34:56 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at aimer-v/127.0.0.1
************************************************************/

显示如上信息便说明 namenode 格式化成功 
</code></pre>


<ul>
<li>然后再将路径切换到 ${HADOOP_HOME}/sbin 的下面</li>
</ul>
<pre><code>
$ ./start-dfs.sh                           # 启动 hdfs 
</code></pre>

<ul>
<li>如若成功启动显示日志信息如下 </li>
</ul>
<pre><code>
root@aimer-v:/hadoop/sbin# ./start-dfs.sh 
Starting namenodes on [localhost]
localhost: starting namenode, logging to /hadoop/logs/hadoop-root-namenode-aimer-v.out
localhost: starting datanode, logging to /hadoop/logs/hadoop-root-datanode-aimer-v.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /hadoop/logs/hadoop-root-secondarynamenode-aimer-v.out
</code></pre>

<ul>
<li>启动 yarn </li>
</ul>
<pre><code>
$ ./start-yarn.sh                          
</code></pre>

<ul>
<li>若 yarn 成功运行显示如下日志信息 </li>
</ul>
<pre><code>
root@aimer-v:/hadoop/sbin# ./start-yarn.sh  &
[1] 5993
root@aimer-v:/hadoop/sbin# starting yarn daemons
starting resourcemanager, logging to /hadoop/logs/yarn-root-resourcemanager-aimer-v.out
localhost: starting nodemanager, logging to /hadoop/logs/yarn-root-nodemanager-aimer-v.out

[1]+  Done                    ./start-yarn.sh
</code></pre>

<ul>
<li>通过输入 jps 命令来查看 Hadoop 相关进程是否处于正常工作的状态</li>
</ul>
<pre><code>
$ jps 
5602 NameNode
6137 NodeManager
5866 SecondaryNameNode
6031 ResourceManager
6445 Jps
</code></pre>

<h3 id="u5B89_u88C5_spark__u4E4B_u524D_u5148_u5B89_u88C5_u597D_u548C_u5B89_u88C5_spark__u7248_u672C_u76F8_u5339_u914D_u7684_scala"><a href="#u5B89_u88C5_spark__u4E4B_u524D_u5148_u5B89_u88C5_u597D_u548C_u5B89_u88C5_spark__u7248_u672C_u76F8_u5339_u914D_u7684_scala" class="headerlink" title="安装 spark 之前先安装好和安装 spark 版本相匹配的 scala"></a>安装 spark 之前先安装好和安装 spark 版本相匹配的 scala</h3><ul>
<li>首先写在系统中默认安装的 scala</li>
</ul>
<pre><code>
$ apt-get remove scala 
</code></pre>

<ul>
<li>将下载到本地的 <a href="http://pan.baidu.com/s/1o6P3TVk" target="_blank" rel="external">scala</a> 压缩包进行解压</li>
</ul>
<pre><code>
$ tar -xvf scala-2.11.7.tgz
</code></pre>

<ul>
<li>修改系统配置文件，将 scala 所在路径追加到系统搜索路径中</li>
</ul>
<pre><code>
$ vi /etc/profile
</code></pre>

<ul>
<li>向文件中追加如下的信息 </li>
</ul>
<pre><code>
export SCALA_HOME=/scala
export PATH=$SCALA_HOME/bin:$PATH
</code></pre>

<h3 id="u5728_hadoop__u7684_u57FA_u7840_u4E0A_u7EE7_u7EED_u5B89_u88C5_spark"><a href="#u5728_hadoop__u7684_u57FA_u7840_u4E0A_u7EE7_u7EED_u5B89_u88C5_spark" class="headerlink" title="在 hadoop 的基础上继续安装 spark"></a>在 hadoop 的基础上继续安装 spark</h3><ul>
<li>解压软件包</li>
</ul>
<pre><code>
tar -xvf spark-1.5.2-bin-hadoop2.6.tgz
</code></pre>

<ul>
<li>修改系统配置文件，将 spark 所在路径添加到系统搜索路径中</li>
</ul>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/profile </span><br><span class="line">export HADOOP_CONF_DIR=/hadoop/etc/hadoop</span><br><span class="line">export SPARK_MASTER=localhost</span><br><span class="line">export SPARK_LOCAL_IP=localhost</span><br><span class="line">export SPARK_HOME=/spark</span><br><span class="line">export SPARK_LIBRARY_PATH=.:<span class="variable">$JAVA</span>_HOME/lib:<span class="variable">$JAVA</span>_HOME/jre/lib:<span class="variable">$HADOOP</span>_HOME/lib/native</span><br><span class="line">export YARN_CONF_DIR=/hadoop/etc/hadoop</span><br><span class="line">export PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK</span>_HOME/bin</span><br><span class="line">export SCALA_HOME=/opt/scala</span><br><span class="line">export PATH=<span class="variable">$SCALA</span>_HOME/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<ul>
<li>最后通过该命令让修改的系统配置信息立即生效</li>
</ul>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure>
<ul>
<li>修改 spark 的配置文件</li>
</ul>
<pre><code>
$ cd ${SPARK_HOME}/conf
$ cp spark-env.sh.template spark-env.sh      # 在这里建议将配置文件的文件模板进行保留，通过创建它的备份的方式来在备份文件上面进行修改
</code></pre>

<ul>
<li>打开 spark-env.sh 文件，然后添加如下的信息</li>
</ul>
<pre><code>
$ vi spark-env.sh                    

export JAVA_HOME=/usr/lib/jvm/java-7-oracle
export SCALA_HOME=/opt/scala
export HADOOP_CONF_DIR=/hadoop/etc/hadoop
</code></pre>


* 通过脚本来启动 spark 相关的服务

<pre><code>
$ cd ${SPARK_HOME}/sbin
$ ./start-all.sh
</code></pre>

<ul>
<li>如果启动成功的话，将会显示出如下的信息 </li>
</ul>
<pre><code>
root@aimer-v:/spark/sbin# ./start-all.sh 
rsync from localhost
rsync: change_dir "/spark/sbin//localhost" failed: No such file or directory (2)
rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1183) [sender=3.1.1]
starting org.apache.spark.deploy.master.Master, logging to /spark/sbin/../logs/spark-root-org.apache.spark.deploy.master.Master-1-aimer-v.out
localhost: starting org.apache.spark.deploy.worker.Worker, logging to /spark/sbin/../logs/spark-root-org.apache.spark.deploy.worker.Worker-1-aimer-v.out

</code></pre>


<ul>
<li>通过输入 jps 命令来查看系统中各个进程的运行状态信息</li>
</ul>
<pre><code>
$ jps

root@aimer-v:/spark/sbin# jps
5470 SecondaryNameNode
5332 DataNode
6911 Worker
6690 Master
5776 NodeManager
5224 NameNode
5669 ResourceManager
6955 Jps
</code></pre>

<ul>
<li>其中的 Master 和 Worker 便是我们刚才启动 Spark 所运行的相关进程</li>
</ul>
<ul>
<li>通过脚本来运行 spark-shell 通过脚本的方式来访问 spark </li>
</ul>
<pre><code>
$ cd  ${SPARK_HOME}/bin
$ ./spark-shell
//  如果正常启动的话，将会显示如下日志信息 
</code></pre>

<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-spark_run.png" alt=""></p>
<p>自此，虚拟机上面 hadoop &amp; spark 的单节点运行环境部署结束 </p>
<hr>
<h2 id="u5728_u4E3B_u673A_u4E0A_u90E8_u7F72_u73AF_u5883"><a href="#u5728_u4E3B_u673A_u4E0A_u90E8_u7F72_u73AF_u5883" class="headerlink" title="在主机上部署环境"></a>在主机上部署环境</h2><h3 id="u642D_u5EFA_WordCounter__u7684_u7F16_u7A0B_u73AF_u5883"><a href="#u642D_u5EFA_WordCounter__u7684_u7F16_u7A0B_u73AF_u5883" class="headerlink" title="搭建 WordCounter 的编程环境"></a>搭建 WordCounter 的编程环境</h3><ul>
<li><p>在这里我们使用的是 scala 编程语言来进行编写 wordcounter 程序  </p>
</li>
<li><p>step 1. 在 Intellij 中创建一个新的 scala 项目</p>
</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/1_.png" alt=""><br><img src="http://7xqz39.com1.z0.glb.clouddn.com/2_.png" alt=""></p>
<ul>
<li><p>step 2. 打开 File -&gt; Project Structure -&gt; 点击最左栏中的 Libraries 选项 –&gt; 绿色的 ‘+’ 按钮</p>
</li>
<li><p>step 3. 将刚刚下载的 spark-1.5.2-bin-hadoop2.6 文件下 spark-1.5.2-bin-hadoop2.6\spark-1.5.2-bin-hadoop2.6\lib\spark-assembly-1.5.2-hadoop2.6.0.jar 文件加载到当前编程环境中</p>
</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/3_.png" alt=""></p>
<ul>
<li>step 4. 设置编译代码生成的 .jar 文件所在的路径， 打开 File -&gt; Project Structure -&gt; 点击最左栏中的 Artifacts 选项 –&gt; 绿色的 ‘+’ 按钮 Jar -&gt; From modules with dependencies ，然后在弹出的 ‘Create JAR from Modules’ 中的 ‘Main Class’ 选中对应的函数入口类文件，在这里我们选的是 SparkWordCount 这个文件</li>
<li></li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/4_.png" alt=""></p>
<ul>
<li>step 5. 为 META-INF/MAINFEST.MF 这个将要生成的配置文件设置路径</li>
<li>step 6. 在 Name 栏中设置将要生成的 .jar 文件的名称， 在 Output directory 一栏中设置 .jar 文件将会输出的路径</li>
<li>step 7. 同时不要忘了将 Build on make 设置有效，最后点击 ok 按钮</li>
<li></li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/7_final_jar.png" alt=""></p>
<ul>
<li>step 8. 编写代码 SparkWordCount.scala 代码如下所示</li>
</ul>
<pre><code>
import org.apache.spark.{SparkConf, SparkContext}

object SparkWordCount {
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("SparkWordCount").setMaster("localhost")
    val sc = new SparkContext(conf)
    val count=sc.textFile(args(0)).filter(line => line.contains("Spark")).count()
    println("count="+count)
    sc.stop()
  }
}
</code></pre>

<ul>
<li>在再次运行代码的过程中出了一点问题: IDE 报错了显示缺少 scala （SDK） 相关的 jar 文件</li>
<li>引发报错的原因是: 之前引用到当前系统中的 SDK 索引没有更新，重新导入一次即可，如下图所示, IDE 重新创建一下索引即可征程编译</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/6_.png" alt=""></p>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/build.png" alt=""></p>
<ul>
<li>step 9. 编译刚刚编写的代码 Build -&gt; Make Project ， 然后到对应的路径下面找 jar 文件</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/result_8.png" alt=""></p>
<h3 id="u5C06_u751F_u6210_u7684_jar__u6587_u4EF6_u4E0A_u4F20_u81F3_u5B89_u88C5_u6709_spark__u7684_u865A_u62DF_u673A_u4E0A"><a href="#u5C06_u751F_u6210_u7684_jar__u6587_u4EF6_u4E0A_u4F20_u81F3_u5B89_u88C5_u6709_spark__u7684_u865A_u62DF_u673A_u4E0A" class="headerlink" title="将生成的 jar 文件上传至安装有 spark 的虚拟机上"></a>将生成的 jar 文件上传至安装有 spark 的虚拟机上</h3><ul>
<li>在对应的路径下创建文件夹，然后将生成的 .jar 文件上传到该文件夹下面</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/upload_9.png" alt=""></p>
<h2 id="u5F00_u59CB_u8FDC_u7A0B_u8C03_u8BD5"><a href="#u5F00_u59CB_u8FDC_u7A0B_u8C03_u8BD5" class="headerlink" title="开始远程调试"></a>开始远程调试</h2><h3 id="u9996_u5148_u5728_u865A_u62DF_u673A_28Linux_29_u7684_u547D_u4EE4_u884C_u4E2D_u8F93_u5165_u547D_u4EE4_u8BA9_spark__u6765_u4EE5_u8C03_u8BD5_u7684_u65B9_u5F0F_u6267_u884C_u4E0A_u4F20_jar__u6587_u4EF6"><a href="#u9996_u5148_u5728_u865A_u62DF_u673A_28Linux_29_u7684_u547D_u4EE4_u884C_u4E2D_u8F93_u5165_u547D_u4EE4_u8BA9_spark__u6765_u4EE5_u8C03_u8BD5_u7684_u65B9_u5F0F_u6267_u884C_u4E0A_u4F20_jar__u6587_u4EF6" class="headerlink" title="首先在虚拟机(Linux)的命令行中输入命令让 spark 来以调试的方式执行上传 jar 文件"></a>首先在虚拟机(Linux)的命令行中输入命令让 spark 来以调试的方式执行上传 jar 文件</h3><pre><code>
$ cd ${SPARK_HOME}/bin
</code></pre> 

<ul>
<li>然后查看虚拟机的 IP 地址信息，我的是 </li>
</ul>
<pre><code>
root@aimer-v:/home/aimer/spark_remote# ifconfig
eth0      Link encap:Ethernet  HWaddr 08:00:27:f5:3e:29  
          inet addr:10.0.2.15  Bcast:10.0.2.255  Mask:255.255.255.0
          inet6 addr: fe80::a00:27ff:fef5:3e29/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:169490 errors:0 dropped:0 overruns:0 frame:0
          TX packets:50036 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:208071948 (208.0 MB)  TX bytes:3995229 (3.9 MB)

eth1      Link encap:Ethernet  HWaddr 08:00:27:e5:6b:20  
          inet addr:192.168.56.113  Bcast:192.168.56.255  Mask:255.255.255.0
          inet6 addr: fe80::a00:27ff:fee5:6b20/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:934783 errors:0 dropped:0 overruns:0 frame:0
          TX packets:458868 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:987944856 (987.9 MB)  TX bytes:42138914 (42.1 MB)

eth2      Link encap:Ethernet  HWaddr 08:00:27:15:4d:1b  
          inet addr:192.168.56.112  Bcast:192.168.56.255  Mask:255.255.255.0
          inet6 addr: fe80::a00:27ff:fe15:4d1b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:390 errors:0 dropped:0 overruns:0 frame:0
          TX packets:840 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:45543 (45.5 KB)  TX bytes:103389 (103.3 KB)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:965869 errors:0 dropped:0 overruns:0 frame:0
          TX packets:965869 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:497637820 (497.6 MB)  TX bytes:497637820 (497.6 MB)
</code></pre>

<h3 id="u5728_u4E0A_u8FF0_u7684_IP__u5730_u5740_u4E2D"><a href="#u5728_u4E0A_u8FF0_u7684_IP__u5730_u5740_u4E2D" class="headerlink" title="在上述的 IP 地址中"></a>在上述的 IP 地址中</h3><ul>
<li>第一个是我用来在虚拟机上面以 NAT 的方式登录互联网的 IP </li>
<li>第二个 IP 地址是多结点分布式部署 spark 集群设定的 IP</li>
<li>第三个 IP 地址是用来进行主机到虚拟机二者之间进行 ssh 远程连接的 IP 地址</li>
<li><p>第四个 主机自循环 IP 地址</p>
</li>
<li><p>因为我们在进行远程调试的时候，是想把虚拟机中的调试信息数据通过端口号传到主机(windows)的上面，</p>
</li>
<li><p>所以选用的输出调试信息的 IP 地址与 ssh 所使用的相同,只不过端口号不同一个是 8888 另一个是 22 罢了</p>
</li>
<li><p>接下来，不要着急运行 jar ，在这里由于 word-counter 这个程序是从 hdfs 上面来读取文本文件的，</p>
</li>
<li><p>所以还需要将输入文本文件上传到 hdfs 的上</p>
</li>
<li><p>首先将本地的文本文件 README.md(我用的是 spark 的 README 文件，随便什么 ASCII 编码的文本文件都可以) 上传到 hdfs 的上面</p>
</li>
</ul>
<pre><code>
$ hdfs dfs -put REAEME.md /
</code></pre>

<ul>
<li>查看文件是否被正确的上传，以及对应的结果路径是否正确的被创建 (在此期间，发现 datanode 没有启动，所以 README.md 这个本地文件并没有正确上传，所以先停掉了 spark ,hadoop , 然后重启 hadoop ，在 hadoop 启动之后又将 spark 进行启动)</li>
</ul>
<pre><code>
$ hdfs dfs -ls /
root@aimer-v:/home/aimer/spark_remote# hdfs dfs -ls /
Found 5 items
-rw-r--r--   1 root supergroup       3593 2016-02-26 16:34 /README.md
drwx-wx-wx   - root supergroup          0 2016-01-01 23:31 /tmp
drwxr-xr-x   - root supergroup          0 2016-01-01 23:53 /user
</code></pre>

<ul>
<li>在输入文件上传，输出数据文件路径分别在 hdfs 上创建好之后便可以输入如下命令</li>
</ul>
<pre><code>
$  ./spark-submit --master spark://aimer-v:7077 --name SparkWordCount --class SparkWordCount --driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8888" --executor-memory 1G /home/aimer/spark_remote/spark_learning.jar hdfs://aimer-v:9000/wordcount/README.md --driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8888"
</code></pre>

<ul>
<li>如果正确运行的话，命令行中会显示如下的信息 </li>
</ul>
<pre><code>
Listening for transport dt_socket at address: 8888
</code></pre>

<h3 id="u7136_u540E_u5728_u672C_u5730_u7684_Intellij__u4E2D_u901A_u8FC7_u5982_u4E0B_u7684_u914D_u7F6E_u6765_u63A5_u6536_u8FDC_u7A0B_u53D1_u6765_u7684_u8C03_u8BD5_u4FE1_u606F_uFF0C_u5B9E_u73B0_u8FDC_u7A0B_u8C03_u8BD5_u529F_u80FD"><a href="#u7136_u540E_u5728_u672C_u5730_u7684_Intellij__u4E2D_u901A_u8FC7_u5982_u4E0B_u7684_u914D_u7F6E_u6765_u63A5_u6536_u8FDC_u7A0B_u53D1_u6765_u7684_u8C03_u8BD5_u4FE1_u606F_uFF0C_u5B9E_u73B0_u8FDC_u7A0B_u8C03_u8BD5_u529F_u80FD" class="headerlink" title="然后在本地的 Intellij 中通过如下的配置来接收远程发来的调试信息，实现远程调试功能"></a>然后在本地的 Intellij 中通过如下的配置来接收远程发来的调试信息，实现远程调试功能</h3><ul>
<li>step 1 Run -&gt; Edit Configurations 配置如下图所示的远程调试配置信息,为这个创建的远程调试设定一个名称 “remote-spark”</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF.png" alt=""></p>
<ul>
<li>step 2 Run -&gt; Debug ‘remote-spark’<br>如果成功连接的话，将会在下面显示如下的信息(不要忘了在本地的代码上打上端点)</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-%E5%90%AF%E5%8A%A8%E8%B0%83%E8%AF%95%E5%91%BD%E4%BB%A4.png" alt=""></p>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/final_result.png" alt=""> </p>
<ul>
<li>同时如果将窗口切换到远程访问界面的话，也会看到对应输出的日志信息(直接截图)</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/final_ssh.png" alt=""></p>
<ul>
<li>step 3 继续调试，直到程序结束，最终结果既不会显示在 IDE 的控制台输出信息中，而是会显示在 linux 的命令提示行中</li>
</ul>
<p><img src="http://7xqz39.com1.z0.glb.clouddn.com/end_ide.png" alt=""><br><img src="http://7xqz39.com1.z0.glb.clouddn.com/count.png" alt=""> </p>
<p>end</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/26/2016.2.26.remote_debug_spark_intellij/" data-id="cil3ik2sz000zh4imrbqmnuim" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/IDEA/">IDEA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Intellij/">Intellij</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/debug/">debug</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.25.spark.manual.translate1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/25/2016.2.25.spark.manual.translate1/" class="article-date">
  <time datetime="2016-02-24T16:00:00.000Z" itemprop="datePublished">2016-02-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/25/2016.2.25.spark.manual.translate1/">Spark 文档翻译1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description: 最近参加了一个<a href="http://ifeve.com/apache-spark/comment-page-1/#comment-26703" target="_blank" rel="external">翻译 spark 文档的小组</a> 打算利用业余时间来补习一下英文，以及通过阅读 spark 文档来系统学习一下 spark 的相关知识，翻译难免有不恰当之处，敬请指正。</p>
<hr>
<p><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#spark-sql-dataframes-and-datasets-guide" target="_blank" rel="external">Spark SQL,DataFrames and Datasets Guide</a></p>
<h1 id="u6982_u8FF0"><a href="#u6982_u8FF0" class="headerlink" title="概述"></a>概述</h1><p>Spark SQL 是 Spark 中用来处理结构化数据的模块。基本抽象数据类型 RDD 所提供的接口不同的是， Spark SQL 的接口则会向 Spark 提供更多关于数据结构和正在进行的计算结构方面额外的信息。事实上， Spark SQL 就是利用这些附带的信息来执行额外的优化操作的。与 Spark SQL相交互的方式有这几种: 通过 SQL 语句，DataFrames 的接口函数和 Dataset 提供的应用程序接口函数。<br>计算数据的时所调用的是同一个引擎，该引擎不会因为你使用编程语言或是调用函数接口的不同而有所变动。这种(引擎调用的)统一化意味着开发者可以轻易地在 Spark 为不同语言提供的函数接口之间进行频繁地切换目的是可以用不同语言中最为地道的的方式来执行数据的转换操作。</p>
<p>在当前页面中所呈现的所有示例和简单的测试数据在 Spark 发布的软件包中均能找到，且可以使用 spark-shell,pyspark shell 或是 sparkR shell 来运行。</p>
<h3 id="SQL-_u7ED3_u6784_u5316_u67E5_u8BE2_u8BED_u8A00"><a href="#SQL-_u7ED3_u6784_u5316_u67E5_u8BE2_u8BED_u8A00" class="headerlink" title="SQL-结构化查询语言"></a>SQL-结构化查询语言</h3><p>Spark SQL 的其中一种使用方式便是用来执行执行最基本 SQL 语法格式或是 HiveQL 语法格式的 SQL 语句的查询。 Spark SQL 同样也具有从已经安装部署好的 Hive (数据仓库)中读取数据这样一种功能。如果想要了解更多关于如何配置 Spark SQL 的这种特性，可以参照 Hive Tables 这一段的文档。当使用另外一种编程语言来运行 SQL 的时候最终的执行结果将会以 DataFrame 的数据结构被返回使用者也可以通过命令行或是 JDBC/ODBC 的方式来与 SQL 接口来进行交互。</p>
<h3 id="DataFrames-_u6570_u636E_u6846"><a href="#DataFrames-_u6570_u636E_u6846" class="headerlink" title="DataFrames-数据框"></a>DataFrames-数据框</h3><p>DataFrame 所指的是由以’列’组织的这样的数据所构成的分布式集合。从理论角度分析，可以把存放于关系型数据库中的数据表比作是 R/Python 语言中的数据框，但是后者在底层表述方面有着更加丰富的优化策略。DataFrames 有着丰富的生成数据来源，像是: 结构化数据文件， Hive 中的数据表，外部数据库或是已经存在于内存中的 RDDs 结构。</p>
<p>(Spark 也为)DataFrame 提供了由 Scala，Java,Python，和R语言编写好的 API 接口。</p>
<h3 id="Datasets-_u6570_u636E_u96C6"><a href="#Datasets-_u6570_u636E_u96C6" class="headerlink" title="Datasets-数据集"></a>Datasets-数据集</h3><p>Dataset 是在 Spark 1.6 版本之后实验性新增的一个接口，目的是为了让基于 RDDs(支持强写入,并能够使用强大的 lambda 表达式) 可以在执行计算时具备和 Spark SQL 一样的引擎优化的能力。一个 Dataset(对象) 可以从 JVM 的对象生成，(生成之后)便可以调用相关的操作方法(像是,map, flatMap,filter,诸如此类的方法)。</p>
<p>Dataset 有一套统一的可被应用于 Scala 和 Java 开发语言中的API接口函数。Python 语言目前还不支持 Dataset 的 API 接口函数，但是由于 Python 本身具备动态编程语言的特性这一优势使使用 Dataset 的 API变为了可能(比如说，你可以通过 Python 的原声语言特sing row.columnName 来直接访问行对象中的属性字段)。Dataset 将会在未来的发行版本中来实现对 Python 语言的完全支持。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/25/2016.2.25.spark.manual.translate1/" data-id="cil3ik2tg001ah4imima90kmb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/doc/">doc</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/official/">official</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/翻译/">翻译</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.19.Google-Test 使用教程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/19/2016.2.19.Google-Test 使用教程/" class="article-date">
  <time datetime="2016-02-18T16:00:00.000Z" itemprop="datePublished">2016-02-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/19/2016.2.19.Google-Test 使用教程/">Google 测试框架 g-Test 使用教程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description: 这篇文章简明介绍了 google 开源的一款 C++ 方向的测试框架 <a href="http://baike.baidu.com/link?url=BaRDfHesKkuurHcqjxM2g8vRMU9udYULmvOLn49k9pr79Il7uj6z7wlcf-BIe4sgJNLKTH8MN8MpMvdZseIEVK" target="_blank" rel="external">Gtest</a> 的使用方法做简单介绍,为后续整理发布的<a href="/">数据库引擎开发项目</a>(目前还没发布到博客中)做单元，模块测试方面的技术支撑。</p>
<hr>
<h2 id="G-Test__u7684_u5B89_u88C5"><a href="#G-Test__u7684_u5B89_u88C5" class="headerlink" title="G-Test 的安装"></a>G-Test 的安装</h2><ul>
<li>通过 github 页面下载 gtest 的源码压缩包,命令如下</li>
</ul>
<pre><code>
   $wget https://github.com/google/googletest/archive/master.zip 
</code></pre>

<ul>
<li>解压之后，在目录下面看到 CMakeList.txt 文件，可知使用的是 cmake 编译工具，保证虚拟机处于联网(NAT模式)，输入命令下载 cmake 编译工具</li>
</ul>
<pre><code>
  $apt-get install cmake 
</code></pre>

<ul>
<li>下载 cmake 结束之后，测试其是否能够正常工作 </li>
</ul>
<pre><code>
$cmake
如果正常工作会显示如下内容
Usage
  cmake [options] <path-to-source>
  cmake [options] <path-to-existing-build>
  Options -C <initial-cache> = Pre-load a script to populate the cache. 
</initial-cache></path-to-existing-build></path-to-source></code></pre>

<p> 编译安装 gTest </p>
<pre><code>
    $ mkdir cmake_dir
    $ cd cmake_dir
    $ cmake ../
    正确编译，显示信息如下
-- The C compiler identification is GNU 4.9.2
-- The CXX compiler identification is GNU 4.9.2
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
...
-- Found Threads: TRUE  
-- Configuring done
-- Generating done
-- Build files have been written to: /gTester/googletest-master/cmake_dir
 </code></pre> 
   在这里我们创建 cmake_dir 文件夹，并在该文件夹的下面执行 cmake 操作的目的是为了让 cmake 编译生成的中间文件与下载的 gTest 的项目文件二者之间分离开，不然会混淆. 在 cmake_dir 文件夹中生成的中间文件如下:

<pre><code>
 CMakeCache.txt  CMakeFiles  cmake_install.cmake  CTestTestfile.cmake  googlemock  Makefile
</code></pre>

<p>   继续输入 make &amp;&amp; make install 来安装 gTest，如正确编译安装显示信息如下:</p>
<pre><code>
 Scanning dependencies of target gmock
[ 14%] Building CXX object googlemock/CMakeFiles/gmock.dir/__/googletest/src/gtest-all.cc.o
[ 28%] Building CXX object googlemock/CMakeFiles/gmock.dir/src/gmock-all.cc.o
Linking CXX static library libgmock.a
...
Install the project...
-- Install configuration: ""
-- Installing: /usr/local/lib/libgmock.a
-- Installing: /usr/local/lib/libgmock_main.a
-- Installing: /usr/local/include/gmock
-- Installing: /usr/local/include/gmock/gmock-generated-actions.h
-- Installing: /usr/local/include/gmock/gmock-cardinalities.h
-- Installing: /usr/local/include/gmock/gmock-actions.h
... 
</code></pre> 

<h2 id="gTest__u7684_u5165_u95E8_u7EA7_u4F7F_u7528_u4F8B_u5B50"><a href="#gTest__u7684_u5165_u95E8_u7EA7_u4F7F_u7528_u4F8B_u5B50" class="headerlink" title="gTest 的入门级使用例子"></a>gTest 的入门级使用例子</h2><ul>
<li>使用 gTest 来编写最简单的测试用例<ul>
<li>首先编写 C++ 文件  </li>
</ul>
</li>
</ul>
<pre><code>
  // test.hpp
#ifndef TEST_HPP__
#define TEST_HPP__

int getValue(int _value);

#endif
</code></pre>

<pre><code>
 // test.cpp
#include "test.hpp"
#include <cstdio>

int getValue( int _value ){
    return _value ;
}
</cstdio></code> </pre>


<ul>
<li>编写包含 gTest库函数的 C++ 测试文件 </li>
</ul>
<pre><code>
#include "test.hpp"
#include "gtest/gtest.h"

// first we test ASSERT_TRUE

void test_ASSERT_TRUE(){
  ASSERT_TRUE(false) ;
}

void test_EXPECT_TRUE(){
   EXPECT_TRUE(false) ;
}

int main( void ){
  test_EXPECT_TRUE();

  return 0;
}

</code></pre>

<ul>
<li>编写 Makefile 文件</li>
</ul>
<pre><code>
GTEST_DIR=/gTester/googletest-master/googletest

USER_DIR= ./

CPPFLAGS += -I$(GTEST_DIR)/include

CXXFLAGS += -g -Wall -Wextra

TESTS = test_tester

GTEST_HEADERS = $(GTEST_DIR)/include/gtest/*.h \
                $(GTEST_DIR)/include/gtest/internal/*.h

all : $(TESTS)

clean :
        rm -f $(TESTS) *.a *.o

GTEST_SRCS_= $(GTEST_DIR)/src/*.cc $(GTEST_DIR)/src/*.h $(GTEST_HEADERS)

gtest-all.o : $(GTEST_SRCS_)
        $(CXX) $(CPPFLAGS) -I$(GTEST_DIR) $(CXXFLAGS) -c \
                $(GTEST_DIR)/src/gtest-all.cc


gtest_main.o : $(GTEST_SRCS_)
        $(CXX) $(CPPFLAGS) -I$(GTEST_DIR) $(CXXFLAGS) -c $(GTEST_DIR)/src/gtest_main.cc  

gtest.a : gtest-all.o
        $(AR) $(ARFLAGS) $@ $^  

gtest_main.a : gtest-all.o gtest_main.o
        $(AR) $(ARFLAGS) $@ $^  


test.o : $(USER_DIR)/test.cpp $(USER_DIR)/test.hpp $(GTEST_HEADERS)
        $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $(USER_DIR)/test.cpp

test_tester.o : $(USER_DIR)/test_tester.cpp $(USER_DIR)/test.hpp $(GTEST_HEADERS)
        $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $(USER_DIR)/test_tester.cpp

test_tester : test.o test_tester.o gtest_main.a
        $(CXX) $(CPPFLAGS) $(CXXFLAG) -pthread  $^ -o $@
</code></pre>

<ul>
<li>输入 make 命令生成可执行文件 test_tester</li>
<li>运行 gTest 的测试文件，查看输出结果</li>
</ul>
<pre><code>
 .//test_tester.cpp:12: Failure
  Value of: false
  Actual: false
  Expected: true 
</code> </pre>

<h2 id="gTest__u4E2D_u65AD_u8A00_u4ECB_u7ECD"><a href="#gTest__u4E2D_u65AD_u8A00_u4ECB_u7ECD" class="headerlink" title="gTest 中断言介绍"></a>gTest 中断言介绍</h2><ul>
<li><p><b>ASSERT_* 的断言函数如果判定最终结果不满足判定输出值，将会发出 断言失败 + 终止程序的结果</b></p>
</li>
<li><p><b>EXPECT_* 的断言函数如果判断最终结果不满足判定输出值，将仅会发出 断言失败 的提示信息</b>    </p>
</li>
</ul>
<h3 id="u57FA_u672C_u65AD_u8A00_u8BF4_u660E"><a href="#u57FA_u672C_u65AD_u8A00_u8BF4_u660E" class="headerlink" title="基本断言说明"></a>基本断言说明</h3><pre><code>
ASSERT_TRUE （condition）； 
ASSERT_FALSE (condition) ；
</code></pre>
上述断言函数是这样的: 括号中的 condition 可以是一个返回结果为布尔值的函数，也可以是一个不二变量，同样也可以是一个逻辑表达式，只要最终返回的结果是布尔值就可以。而两个函数 ASSERT_TRUE 要求这个布尔值必须是 TRUE/真值，如果不是真便会输出'致命错误'并退出当前正在执行的函数。 ASSERT_FALSE 方法刚好相反，它期待的是一个 FALSE/假值，如果不满足同样输出'致命错误'信息，并退出当前正在执行的方法(程序)。

<pre><code>
   EXPECT_TRUE(condition) ;
   EXPECT_FALSE(condition) ;
</code></pre>
上述函数的断言是这样的: 如果括号中的 condition 变量返回的布尔值与断言期待的布尔值不同的话，不会退出当前正在执行的方法/程序。 它会继续允许程序的继续运行，但是会输出执行错误的提示信息（如果错误信息流定向是控制台显示器的话）

### 基于两值比较的断言函数说明
+ 在基于而知比较的断言函数中，传入的参数必须要满足下面两种条件中的一种
  + 是基本类型，可以直接进行逻辑比较

  + 如果是符合类似(class ,struct)是需要重载比较运算符的

  + 需要注意的是，如果传入的是指针类型的话，判定的并不是指针指向的数值内容是否相同，而是会判定指针是否指向同一块内存空间
  + <b>如果需要判定指针指向字符串的逻辑关系，不要使用这一系列的断言函数</b> <br>


<pre><code>
    ASSERT_EQ(expected, actual) ；  expected==actual
    ASSERT_NE(expected, actual) ；  expected!=actual
    ASSERT_LT(expected, actual) ；  expected 小于 actual, LT(less than)
    ASSERT_LE(expected, actual) ；  expected 小于等于 actual, LE(less equal)
    ASSERT_GT(expected, actual) ；  expected 大于 actual, GT(greater than)
    ASSERT_GE(expected, actual) ；  expected 大于等于 actual, GE(greater equal)
</code></pre>

<pre><code>
  EXPECT_EQ(expected, actual) ；
  EXPECT_NE(expected, actual) ；
  EXPECT_LT(expected, actual) ；
  EXPECT_LE(expected, actual) ；
  EXPECT_GT(expected, actual) ；
  EXPECT_GE(expected, actual) ；
</code></pre>



<h3 id="u57FA_u4E8E_u5B57_u7B26_u4E32_u7684_u6BD4_u8F83_u65AD_u8A00_u8BF4_u660E"><a href="#u57FA_u4E8E_u5B57_u7B26_u4E32_u7684_u6BD4_u8F83_u65AD_u8A00_u8BF4_u660E" class="headerlink" title="基于字符串的比较断言说明"></a>基于字符串的比较断言说明</h3><pre><code>
  ASSERT_STREQ(str1,str2); str1's content = str2's content
  ASSERT_STRNE(str1,str2); str1's content != str2's content
 ASSERT_STRCASEEQ(str1,str2); str1's content = str2's content ,ignoring characters case
 ASSERT_STRCASENE(str1,str2); ignoring string characters' case, str1's content != str2's content 
</code></pre>



      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/19/2016.2.19.Google-Test 使用教程/" data-id="cil3ik2tr001ih4immvkjpx6r" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/">C++</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gtest/">Gtest</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/gtest/">gtest</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/manual/">manual</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tutorial/">tutorial</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/测试/">测试</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.18.dht.note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/18/2016.2.18.dht.note/" class="article-date">
  <time datetime="2016-02-17T16:00:00.000Z" itemprop="datePublished">2016-02-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/18/2016.2.18.dht.note/">DHT Chord 理论学习笔记 1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:</p>
<p>本篇博客记录的是P2P 对等计算中基于 DHT 拓扑结构中的 Chord 算法理论信息，目的是为<a href="/">基于Chord算法的P2P 自感应系统</a>代码做理论支撑</p>
<hr>
<h1 id="u540D_u8BCD_u6982_u5FF5"><a href="#u540D_u8BCD_u6982_u5FF5" class="headerlink" title="名词概念"></a>名词概念</h1><h2 id="DHT__u662F_u4EC0_u4E48__3F"><a href="#DHT__u662F_u4EC0_u4E48__3F" class="headerlink" title="DHT 是什么 ?"></a>DHT 是什么 ?</h2><p>DHT 是对等计算(Peer-to-Peer,P2P) 技术中拓扑结构中的一种，叫做<b>全分布式结构化结构</b>(decentralized structured topology),简称为 DHT，又称作<b>分布式哈希表</b>(distributed hash table)。<br></p>
<p>另外几种拓扑结构分别是<b>中心化拓扑结构</b>(centralized topology),<b>全分布式非结构化结构</b>(decentralized unstructured topology),<b>半分布式结构</b>(partially decentralized topology)。</p>
<h2 id="DHT__u8F83_u6BD4_u5176_u4ED6_u62D3_u6251_u7ED3_u6784_u6709_u54EA_u4E9B_u7279_u70B9_3F"><a href="#DHT__u8F83_u6BD4_u5176_u4ED6_u62D3_u6251_u7ED3_u6784_u6709_u54EA_u4E9B_u7279_u70B9_3F" class="headerlink" title="DHT 较比其他拓扑结构有哪些特点?"></a>DHT 较比其他拓扑结构有哪些特点?</h2><p>DHT 结构可以自适应的支持网络中节点动态地加入/退出，并且扩展性、鲁棒性、结点ID 分配的均匀性和自组织能力都很好。同时DHT由于自身结构的特点可以提供精确的发现和定位网络中结点资源的功能。</p>
<h2 id="DHT__u90FD_u53EF_u4EE5_u7528_u6765_u505A_u4EC0_u4E48__3F"><a href="#DHT__u90FD_u53EF_u4EE5_u7528_u6765_u505A_u4EC0_u4E48__3F" class="headerlink" title="DHT 都可以用来做什么 ?"></a>DHT 都可以用来做什么 ?</h2><p>可以基于 DHT 来建立复杂的服务，例如分散式档案系统、点对点技术档案分享系统、网页的快速抓取、数据的缓存系统、网络中任意结点数据传输、网域名城系统和即时通讯系统等等。 </p>
<h2 id="DHT__u7531_u54EA_u4E9B_u5143_u7D20_u6784_u6210"><a href="#DHT__u7531_u54EA_u4E9B_u5143_u7D20_u6784_u6210" class="headerlink" title="DHT 由哪些元素构成"></a>DHT 由哪些元素构成</h2><h3 id="u64CD_u4F5C/_u65B9_u6CD5_3A_Put_28key_2Cdata_29_2C_Get_28key_29"><a href="#u64CD_u4F5C/_u65B9_u6CD5_3A_Put_28key_2Cdata_29_2C_Get_28key_29" class="headerlink" title="操作/方法: Put(key,data), Get(key)"></a>操作/方法: Put(key,data), Get(key)</h3><p> 既然你已经知道了 DHT 就是我们常说的分布式哈希表，那么结合哈希表的’存入’,’读出’的操作特性，便可以推知 DHT 的操作方法也不外乎这两个(put,get)。</p>
<p> 更加详细的说明在介绍 Chord 算法之后再来补充。</p>
<h2 id="Chord__u662F_u4EC0_u4E48__3F"><a href="#Chord__u662F_u4EC0_u4E48__3F" class="headerlink" title="Chord 是什么 ?"></a>Chord 是什么 ?</h2><p> Chord 是基于 DHT 数据结构的分布式算法，如果说 DHT 为分布式系统查询提供 Put , Get 接口封装的话，那么 Chord 便为 DHT 中为 Get,Put 两种两种方法提供底层实现的算法。 </p>
<p> 二者的关系如下图所示</p>
<p> <img src="http://7xqz39.com1.z0.glb.clouddn.com/2016.2.17.dht.1.png" alt=""></p>
<ul>
<li><p>在 Chord 算法将每台主机抽象成结点(Node)，同时为了保证结点在网络中的唯一性， 使用 Node-ID 数字序列来作为结点的唯一标识。</p>
</li>
<li><p>Chord 将网络中处于’在线’状态的计算机(结点)，按照<b>Node-ID</b>数值的大小排列，从逻辑上构成一个首位相连的环形结构。</p>
</li>
<li><p>为了方便在网络中每台’在线’结点上资源的搜索，每个结点上面还存放用来存放其他结点信息的<b>路由表</b>。</p>
</li>
<li><p>其中逻辑环中的主机总数(结点数目)和结点 ID 号码的位数都有关系:</p>
</li>
</ul>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Node</span><span class="identifier"></span><span class="title">-ID</span> 二进制位数 = m</span><br><span class="line"></span><br><span class="line">逻辑环中最大容纳主机(结点)个数 = <span class="number">2</span>^m 个</span><br><span class="line"></span><br><span class="line"><span class="keyword">Node</span><span class="identifier"></span><span class="title">-ID</span> 取值范围 = [<span class="number">0</span>,<span class="number">2</span>^m -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">Node</span><span class="identifier"> </span><span class="title">上面的 finger-table</span>(路由表) 维护的表项个数为 m 个</span><br><span class="line"></span><br><span class="line">Finger-table 的表项中记录其他 <span class="keyword">Node</span><span class="identifier"></span><span class="title">-ID</span> 的ID间隔为 <span class="number">2</span>^i (<span class="number">0</span> <span class="tag">&lt;=i &lt;= m-1)</span></span><br></pre></td></tr></table></figure>
<p> P2P 网络中 Chord 环状结构图示：下图便是一个 m 为 6 的Chord 拓扑环和环中Node-ID = 8 结点上所维护的 finger table 图示</p>
<p> <img src="http://cdn3.infoqstatic.com/statics_s1_20160216-0153/resource/news/2014/12/Chord-p2p-network-dht/zh/resources/1202000.png" alt=""></p>
<h2 id="Chord__u6784_u6210_u6570_u636E_u7ED3_u6784_u4ECB_u7ECD"><a href="#Chord__u6784_u6210_u6570_u636E_u7ED3_u6784_u4ECB_u7ECD" class="headerlink" title="Chord 构成数据结构介绍"></a>Chord 构成数据结构介绍</h2><h3 id="u540E_u7EE7_u7ED3_u70B9_u5217_u8868_-_sucessor_node_list"><a href="#u540E_u7EE7_u7ED3_u70B9_u5217_u8868_-_sucessor_node_list" class="headerlink" title="后继结点列表 - sucessor node list"></a>后继结点列表 - sucessor node list</h3><ul>
<li><p>何谓后继结点? </p>
<ul>
<li>后继结点(successor)指的是 Chord 逻辑环中处于在线状态的 Node-ID 数值 &gt;= 当前结点 Node-ID 的结点所构成的结点集合中 Node-ID 数值最小的结点变叫做当前结点的后继结点-它只有一个。列表中的其他的节点都是 Node-ID &gt; 当前结点的 Node-ID。</li>
</ul>
</li>
</ul>
<ul>
<li>这么说有点混乱,举个例子: 就拿上图而言，我们设 N14 为当前节点，那么对于 N14 来说整个 Chord 环中 Node-ID 大于等于它所构成的结点集合是 {N21,N32,N38,N42,N48,N51,N56}。</li>
</ul>
<ul>
<li>{N21,N32,N38,N42,N48,N51,N56}  这个列表便是当前 N14的后继结点列表 ，而其中 Node-ID 号码最小的是 N21 , 那么 N21 便可以称作是 N14 的后继结点。</li>
</ul>
<ul>
<li><b>Chord 逻辑环中所提及的结点必须是处于’上线’/live 状态的节点。 Chord 中将处于在线状态的结点作为环中结点进行添加，如果不处于在线状态是不会将它加入逻辑环结构中的。 如果一个结点存活着进入到环中，然后由于某种原因崩溃/宕机了，那么它会被从环中踢出去的。</b> </li>
</ul>
<ul>
<li>后继结点列表是构成 Chord 网络的主要数据结构，当前结点可以借助于后继结点列表中记录的信息来直接’跳转’到它的后继结点上面，就像是 C++ 中通过指针进行地址跳转一样。</li>
</ul>
<ul>
<li><p>后继结点列表越大越好吗？</p>
<ul>
<li><p>后接结点列表中存放的表项越多整个环形网络搜索到目标资源的可靠性越高，设想如果通过当前结点可以’跳到’更多的结点的上面，想必在环形网络中搜索到目标资源的命中率越高。</p>
</li>
<li><p>不过，这些是相对于网络数据流量而言的，维护的列表越大，网络负担也就越重。从一个结点发出的查询越多(可跳转到的结点越多)，该结点的流量相比也会越大。</p>
</li>
</ul>
</li>
</ul>
<h3 id="u524D_u9A71_u7ED3_u70B9_-_predecessor_node"><a href="#u524D_u9A71_u7ED3_u70B9_-_predecessor_node" class="headerlink" title="前驱结点 - predecessor node"></a>前驱结点 - predecessor node</h3><ul>
<li><p>何谓前驱结点?</p>
<ul>
<li>在了解何为后继结点之后，前驱结点的概念也明朗了很多。它指的是 Node-ID &lt; 当前结点 Node-ID 的所有结点集合中， Node-ID 最小的那个便是当前结点的前驱结点</li>
</ul>
</li>
</ul>
<ul>
<li><p>如果某个结点没有 Node-ID &lt; 它的 Node-ID 的结点的话，那么便选取整个 Chord 网络中 Node-ID 号码最大的结点作为它的前驱结点。N8 便是例子，它的前驱结点是 N56。 </p>
</li>
<li><p>这种特例用在后继结点上也是一样:如果在 Chord 网络中找不到 Node-ID &gt; 它的 Node-ID 结点的话，就选取 Chord 网络中 Node-ID 最小的 Node-ID 所标识的结点作为它的后继结点。例如 N56 结点的后继结点便是 N8.</p>
</li>
</ul>
<h3 id="u8DEF_u7531_u8868_-_finger_table"><a href="#u8DEF_u7531_u8868_-_finger_table" class="headerlink" title="路由表 - finger table"></a>路由表 - finger table</h3><ul>
<li><p>何谓路由表? </p>
<p>路由表主要用来提高结点和资源信息的查询路由的速度，类似于 linux 中用来记录 IP 和 IP 所映射的域名的路由表，因此得名。 就是为了根据当前结点可以快速的跳转到其他结点上而记录的其他结点的{结点名称:网络地址} 这样映射关系的表项的二维表格。</p>
</li>
</ul>
<h4 id="u8DEF_u7531_u8868_u8868_u9879"><a href="#u8DEF_u7531_u8868_u8868_u9879" class="headerlink" title="路由表表项"></a>路由表表项</h4><p>   路由表中表项主要存放了一下几种信息:</p>
<ul>
<li><p>start :    (n+2^(k-1)) mode 2^m ; (1&lt;= k &lt;= m )起始查询结点</p>
</li>
<li><p>interval :    [finger[i].start,finger[i+1].start) 区间范围</p>
</li>
<li><p>node : Chord 网络中第一个 Node-ID &gt;= start 结点的后继结点</p>
</li>
<li><p>successor : Chord 网络中结点的直接后继结点</p>
</li>
<li><p>predecessor : Chord 环形网络中结点的直接前驱结点</p>
</li>
</ul>
<p>end</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/18/2016.2.18.dht.note/" data-id="cil3ik2u4001vh4imsi093ja9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chord/">Chord</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DHT/">DHT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/P2P/">P2P</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/note/">note</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/theory/">theory</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.17.upload_picture" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/17/2016.2.17.upload_picture/" class="article-date">
  <time datetime="2016-02-16T16:00:00.000Z" itemprop="datePublished">2016-02-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/17/2016.2.17.upload_picture/">如何使用七牛存储来为你的 gihub 博客中添加图片</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:<br>作为一个截图狂魔的我，在写博客的时候为了让内容描述更加的简洁，都会上传大量的图片实例。<br>但是自从换成了 github 上面的博客之后，为了节省空间(主要是技术问题…)，一直都没有上传图片(背景图片除外！)<br>近期写的<a href="https://kylin27.github.io/2016/02/18/2016.2.18.dht.note/">DHT 这篇博客</a>十分需要配图说明，所以在这篇博客中将如何使用七牛存储来为自己的博客中添加图片的步骤记录一下。</p>
<hr>
<h1 id="u9996_u5148_u6CE8_u518C_u7533_u8BF7_u4E03_u725B_u7684_u8D26_u53F7"><a href="#u9996_u5148_u6CE8_u518C_u7533_u8BF7_u4E03_u725B_u7684_u8D26_u53F7" class="headerlink" title="首先注册申请七牛的账号"></a>首先注册申请<a href="https://portal.qiniu.com/signin" target="_blank" rel="external">七牛</a>的账号</h1><ul>
<li>在注册的时候，推荐将自己的 github 账号和七牛二者进行绑定。</li>
<li>注册成功并登录之后，需要配置空间，也就是为你的空间起域名，空间选择’公开’这样可以确保通过 github 上的链接信息可以直接访问</li>
<li>点击内容管理，然后从本地上传一张图片，会在右边窗口栏中看到这张图片的外链地址信息，我的是<a href="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-test.png" target="_blank" rel="external">这个</a> 点击它便可以看到刚刚上传的截图信息了</li>
</ul>
<h1 id="u7136_u540E_u5C06_u5916_u94FE_u5730_u5740_u6DFB_u52A0_u5230_u535A_u5BA2_u4E2D"><a href="#u7136_u540E_u5C06_u5916_u94FE_u5730_u5740_u6DFB_u52A0_u5230_u535A_u5BA2_u4E2D" class="headerlink" title="然后将外链地址添加到博客中"></a>然后将外链地址添加到博客中</h1><p> <code>加载图片的格式为 ![](刚才七牛网站空间上传图片所生成的外链地址)</code></p>
<p> <img src="http://7xqz39.com1.z0.glb.clouddn.com/tutorial-test.png" alt="">  </p>
<p> 这样便可将图片展现在博客中</p>
<p> end</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/17/2016.2.17.upload_picture/" data-id="cil3ik2ug0025h4im8jvb61fi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/blog/">blog</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/github/">github</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hexo/">hexo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/picture/">picture</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/七牛/">七牛</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.14.docker_spark" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/14/2016.2.14.docker_spark/" class="article-date">
  <time datetime="2016-02-13T16:00:00.000Z" itemprop="datePublished">2016-02-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/14/2016.2.14.docker_spark/">使用 docker 来构建 spark 集群</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:<br>在<a href="https://kylin27.github.io/2016/02/13/2016.2.13.docker_install/">上一博客</a>中介绍了如何在 ubuntu 上面部署 docker 系统，以及 docker 的基本命令; 在本篇博客中将会介绍如何利用 docker-hub 上的资源来快速搭建一个 spark 集群</p>
<hr>
<h1 id="u5982_u4F55_u4F7F_u7528_dockerfile__u6765_u751F_u6210_docker__u955C_u50CF_u6587_u4EF6"><a href="#u5982_u4F55_u4F7F_u7528_dockerfile__u6765_u751F_u6210_docker__u955C_u50CF_u6587_u4EF6" class="headerlink" title="如何使用 dockerfile 来生成 docker 镜像文件"></a>如何使用 dockerfile 来生成 docker 镜像文件</h1><p> 在后续的步骤中有一个镜像文件是无法直接从 docker-hub 的镜像库中直接下载的，但是可以从 github 上面下载到该镜像文件的 dockerfile 文件。 所以在这里介绍一下如何使用 dockerfile 来创建 docker 镜像文件。 如果今后需要的话，将会详细介绍一下如何根据自己的需要来定制编写自己的 dockerfile .</p>
<h3 id="docker_build"><a href="#docker_build" class="headerlink" title="docker build"></a>docker build</h3><p> 用来将指定路径的中 dockerfile 生成 docker 镜像文件</p>
 <pre>
 docker build -t="amplab/apache-hadoop-hdfs-precise:1.2.1" . 

 // 上述命令会搜索当前路径，看是否有 dockerfile 文件，如果有，那么执行该 dockerfile 文件，并根据该 dockerfile 文件生成
 // docker 镜像文件。同时又将该镜像文件打上名为 'amplab/apache-hadoop-hdfs-precise:1.2.1' 的标签
 // 由于后面会通过 github 上面提供的 deploy.sh 脚本来构建 spark 系统，所以尽最大可能的保持 hadoop 的镜像文件的名称一致性 
 </pre>


<h1 id="u4ECE_docker-hub__u4E2D_u4E0B_u8F7D_u955C_u50CF_u6587_u4EF6"><a href="#u4ECE_docker-hub__u4E2D_u4E0B_u8F7D_u955C_u50CF_u6587_u4EF6" class="headerlink" title="从 docker-hub 中下载镜像文件"></a>从 docker-hub 中下载镜像文件</h1><p>首先确保正确登录 docker-hub 账号<br>其实我安装 spark 的主要目的是为了使用 spark 提供的 GraphX 和 mllib 这两个工具，而 mllib 中在 spark-0.9 之后才支持，<br>所以，在这里我安装的是 spark-1.0.0 版本<br><b>在执行 pull 命令之前,我开启了翻墙的软件,这样可以节省时间</b></p>
<pre>
sudo docker pull amplab/apache-hadoop-hdfs-precise:1.2.1   
// 这个镜像在 docker-hub 上面找不到，所以需要根据 github 可以获得的 Dockerfile 来构建其镜像文件

$docker pull amplab/dnsmasq-precise:1.0.0
$docker pull amplab/spark-worker:1.0.0
$docker pull amplab/spark-master:1.0.1
$docker pull amplab/spark-shell:1.0.1

$docker images                // 通过该命令查看系统中的镜像文件

REPOSITORY               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
ubuntu_14                wget                44552cea1d79        7 hours ago         187.9 MB
ubuntu                   14.04               8693db7e8a00        3 weeks ago         187.9 MB
amplab/spark-shell       1.0.0               c18acb8d81a0        20 months ago       964.3 MB
amplab/spark-worker      1.0.0               6f77966546ee        20 months ago       964.3 MB
amplab/spark-master      1.0.0               a43b969cfeff        20 months ago       964.3 MB
amplab/dnsmasq-precise   latest              d9cdba2ae123        23 months ago       205.8 MB

</pre>

<h1 id="u4ECE_git-hub__u4E0A_u9762_u4E0B_u8F7D_u8FD0_u884C_docker__u955C_u50CF_u6587_u4EF6_u7684_u811A_u672C"><a href="#u4ECE_git-hub__u4E0A_u9762_u4E0B_u8F7D_u8FD0_u884C_docker__u955C_u50CF_u6587_u4EF6_u7684_u811A_u672C" class="headerlink" title="从 git-hub 上面下载运行 docker 镜像文件的脚本"></a>从 git-hub 上面下载运行 docker 镜像文件的脚本</h1><pre>
$wget https://github.com/amplab/docker-scripts/archive/master.zip
$unzip master.zip
</pre>

<h1 id="u542F_u52A8_spark__u96C6_u7FA4"><a href="#u542F_u52A8_spark__u96C6_u7FA4" class="headerlink" title="启动 spark 集群"></a>启动 spark 集群</h1><p>将路径切换到包含 /deploy 文件夹的路径下面</p>
<pre>
./deploy/deploy.sh -i amplab/spark:1.0.0 -w 3

$docker ps                 // 通过该命令来查看系统中正在运行的容器信息

CONTAINER ID        IMAGE                           COMMAND                CREATED              STATUS              PORTS                NAMES
855415af179d        amplab/spark-shell:1.0.0        "/root/spark_shell_f   About a minute ago   Up About a minute   8888/tcp             cocky_meitner           
5bb8f871e474        amplab/spark-shell:1.0.0        "/root/spark_shell_f   2 minutes ago        Up 2 minutes        8888/tcp             modest_brown            
2c2d49565559        amplab/spark-worker:1.0.0       "/root/spark_worker_   5 minutes ago        Up 5 minutes        8888/tcp             silly_ptolemy           
24b16b64e6ad        amplab/spark-worker:1.0.0       "/root/spark_worker_   5 minutes ago        Up 5 minutes        8888/tcp             compassionate_lalande   
25efa7bbeb20        amplab/spark-worker:1.0.0       "/root/spark_worker_   5 minutes ago        Up 5 minutes        8888/tcp             happy_curie             
1ba8d72a6cd2        amplab/spark-master:1.0.0       "/root/spark_master_   6 minutes ago        Up 6 minutes        7077/tcp, 8080/tcp   kickass_jones           
3a8c3a8906df        amplab/dnsmasq-precise:latest   "/root/dnsmasq_files   6 minutes ago        Up 6 minutes 

</pre>

<p>具体的参数解释可以戳<a href="https://github.com/amplab/docker-scripts#testing" target="_blank" rel="external">这里</a><br>-w 是用来指定 spark 运行之后对应的 worker 进程个数<br>从上面输入 docker ps 命令之后显示出来的信息可以推知，我们总共创建了: spark-shell , spark-worker , spark-master, dns<br>这些容器运行，但是没有 hadoop 运行, 于是在熟悉上述流程的我又查了其他的几个spark 集群镜像文件，<a href="https://hub.docker.com/r/sequenceiq/spark/" target="_blank" rel="external">找了一个合适的</a> 接下来试试这个镜像文件好了… </p>
<hr>
<h1 id="u4E0D_u8FC7_u5148_u6765_u5C06_u5F53_u524D_u7CFB_u7EDF_u4E2D_u7684_u6240_u6709_u8FD0_u884C_u5BB9_u5668_u505C_u6B62"><a href="#u4E0D_u8FC7_u5148_u6765_u5C06_u5F53_u524D_u7CFB_u7EDF_u4E2D_u7684_u6240_u6709_u8FD0_u884C_u5BB9_u5668_u505C_u6B62" class="headerlink" title="不过先来将当前系统中的所有运行容器停止"></a>不过先来将当前系统中的所有运行容器停止</h1><pre>
// 同样现将路径切换到 ./deploy 文件夹的路径下面
$ ./deploy/kill_all.sh spark
$ ./deploy/kill_all.sh namespace
</pre>

<hr>
<h1 id="u5C06_u8BE5_u955C_u50CF_u6587_u4EF6_u4E0B_u8F7D_u5230_u672C_u5730"><a href="#u5C06_u8BE5_u955C_u50CF_u6587_u4EF6_u4E0B_u8F7D_u5230_u672C_u5730" class="headerlink" title="将该镜像文件下载到本地"></a>将该镜像文件下载到本地</h1><pre>
$docker pull sequenceiq/spark:v1.6.0onHadoop2.6.0
成功下载显示信息:
...
95d969caad90: Download complete 
2d727ce74b86: Download complete 
28c9338da9a6: Download complete 
cb7d9861a895: Download complete 
73bb712333d9: Download complete 
a466bc76549f: Download complete 
441cf02fdf7d: Download complete 
056efae329d8: Download complete 
Status: Downloaded newer image for sequenceiq/spark:v1.6.0onHadoop2.6.0
</pre>

<h1 id="u4ECE_docker__u955C_u50CF_u6587_u4EF6_u751F_u6210_u5E76_u8FD0_u884C_u5BB9_u5668"><a href="#u4ECE_docker__u955C_u50CF_u6587_u4EF6_u751F_u6210_u5E76_u8FD0_u884C_u5BB9_u5668" class="headerlink" title="从 docker 镜像文件生成并运行容器"></a>从 docker 镜像文件生成并运行容器</h1><p>先来查看一下当前系统中所有的镜像文件</p>
<pre>
$docker images     // 先来查看一下当前系统中所有的镜像文件
REPOSITORY               TAG                   IMAGE ID            CREATED             VIRTUAL SIZE
ubuntu_14                wget                  44552cea1d79        24 hours ago        187.9 MB
ubuntu                   14.04                 8693db7e8a00        3 weeks ago         187.9 MB
sequenceiq/spark         v1.6.0onHadoop2.6.0   056efae329d8        5 weeks ago         2.877 GB
amplab/spark-shell       1.0.0                 c18acb8d81a0        20 months ago       964.3 MB
amplab/spark-worker      1.0.0                 6f77966546ee        20 months ago       964.3 MB
amplab/spark-master      1.0.0                 a43b969cfeff        20 months ago       964.3 MB
amplab/dnsmasq-precise   latest                d9cdba2ae123        23 months ago       205.8 MB
</pre>

<p>再运行镜像文件生成容器实例</p>
<pre>
$docker run -it sequenceiq/spark:v1.6.0onHadoop2.6.0  bash 

成功运行显示信息:
Starting sshd:                                             [  OK  ]
Starting namenodes on [1f25c1d3d790]
1f25c1d3d790: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-1f25c1d3d790.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-1f25c1d3d790.out
Starting secondary namenodes [0.0.0.0]
<b>上述 docker 运行命令作用是是从刚刚下载到本地的 docker 镜像文件中生成 docker 容器(该容器中就包含部署好了的 hadoop 和 spark 软件)；
生成容器之后，登录到该容器中，并运行 bash 命令</b>

成功登录显示信息:
bash-4.1# ls     // <b>先显示一下容器中的基本信息 </b>      
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  pam-1.1.1-17.el6.src.rpm  proc  root  rpmbuild  sbin  selinux  srv  sys  tmp  usr  var
bash-4.1# jps     // <b>然后查看一下容器系统中运行的进程都有什么。 可以看出有 Hadoop 节点和 Spark 等相关进程在运行</b> 
562 NodeManager
353 SecondaryNameNode
109 NameNode
183 DataNode
636 Jps
482 ResourceManager
</pre>

<h1 id="u8FD0_u884C_spark__u4E2D_u7684_counter__u6D4B_u8BD5_u7A0B_u5E8F"><a href="#u8FD0_u884C_spark__u4E2D_u7684_counter__u6D4B_u8BD5_u7A0B_u5E8F" class="headerlink" title="运行 spark 中的 counter 测试程序"></a>运行 spark 中的 counter 测试程序</h1><pre>
<b>首先需要运行一下 spark-shell , 直接在当前 bash 命令行中输入如下命令 </b>
$spark-shell \
 --master yarn-client \
 --driver-memory 1g \
 --executor-memory 1g \
 --executor-cores 1

<b>如果成功，将会显示如下信息:</b>

16/02/14 02:57:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/02/14 02:57:03 INFO spark.SecurityManager: Changing view acls to: root
16/02/14 02:57:03 INFO spark.SecurityManager: Changing modify acls to: root
16/02/14 02:57:03 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/14 02:57:04 INFO spark.HttpServer: Starting HTTP Server
16/02/14 02:57:04 INFO server.Server: jetty-8.y.z-SNAPSHOT
16/02/14 02:57:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58832
16/02/14 02:57:04 INFO util.Utils: Successfully started service 'HTTP class server' on port 58832.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.0
      /_/

Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_51)
Type in expressions to have them evaluated.
... 后面反正还有挺多，最后会看到 scala> 命令行提示输入符

<b>我们来测试一个最简单的计数程序调用好了</b>

scala> sc.parallelize( 1 to 1000).count()
16/02/14 03:01:56 INFO spark.SparkContext: Starting job: count at <console>:28
16/02/14 03:01:56 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:28) with 2 output partitions
16/02/14 03:01:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at <console>:28)
16/02/14 03:01:56 INFO scheduler.DAGScheduler: Parents of final stage: List()
16/02/14 03:01:56 INFO scheduler.DAGScheduler: Missing parents: List()
16/02/14 03:01:56 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at <console>:28), which has no missing parents
16/02/14 03:01:57 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1096.0 B, free 1096.0 B)
16/02/14 03:01:57 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 804.0 B, free 1900.0 B)
16/02/14 03:01:57 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.10:48410 (size: 804.0 B, free: 517.4 MB)
16/02/14 03:01:57 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
16/02/14 03:01:57 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at <console>:28)
16/02/14 03:01:57 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
16/02/14 03:01:58 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 42ba3f37ce84, partition 0,PROCESS_LOCAL, 2078 bytes)
16/02/14 03:01:58 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 42ba3f37ce84, partition 1,PROCESS_LOCAL, 2135 bytes)
16/02/14 03:02:04 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 42ba3f37ce84:58577 (size: 804.0 B, free: 517.4 MB)
16/02/14 03:02:04 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 42ba3f37ce84:36276 (size: 804.0 B, free: 517.4 MB)
16/02/14 03:02:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11580 ms on 42ba3f37ce84 (1/2)
16/02/14 03:02:09 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11454 ms on 42ba3f37ce84 (2/2)
16/02/14 03:02:09 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/14 03:02:09 INFO scheduler.DAGScheduler: ResultStage 0 (count at <console>:28) finished in 11.657 s
16/02/14 03:02:09 INFO scheduler.DAGScheduler: Job 0 finished: count at <console>:28, took 13.058068 s
res0: Long = 1000
</console></console></console></console></console></console></console></pre>

<p> 这样一个 spark 集群就搭建好了，如果需要把当前对容器做出的修改同步到原有的镜像文件(推荐重新另存一个新的镜像文件)，可以使用<a href="https://kylin27.github.io/2016/02/13/2016.2.13.docker_install/">上一篇博客中</a>介绍的 docker commit 这个命令</p>
<h1 id="u5173_u4E8E_u6536_u5C3E_u5DE5_u4F5C"><a href="#u5173_u4E8E_u6536_u5C3E_u5DE5_u4F5C" class="headerlink" title="关于收尾工作"></a>关于收尾工作</h1><p>当前所处的状态是 scala&gt; 的命令行，输入 exit 便可以退出当前 scala 命令行交互的状态；<br>再次输入 exit (一次或是多次) 便可以退出当前登录的 spark-hadoop 集群容器，当然容器在你退出之后便会’消亡’,也就是不运行了系统回收它的资源咯，输入 docker ps 便查看不到容器信息；<br>如果在实际工作中推荐的做法是，在退出容器之前，在另一个远程访问终端内，将该容器的状态信息进行保存(归档或是生成镜像文件，如果乐意也可以将生成的镜像文件提交到 docker-hub 的上面)</p>
<p>总之，博客中很多地方写的很啰嗦啦，因为我喜欢在自己经常犯的错误的地方啰嗦几句，不喜欢的话，来打我啊~<br>end</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/14/2016.2.14.docker_spark/" data-id="cil3ik2uq002dh4imtni36087" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cluster/">cluster</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dockerfile/">dockerfile</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.13.docker_install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/13/2016.2.13.docker_install/" class="article-date">
  <time datetime="2016-02-12T16:00:00.000Z" itemprop="datePublished">2016-02-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/13/2016.2.13.docker_install/">在 Ubuntu 上面安装部署 docker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description: 本篇博客简单记录一下在 ubuntu 上安装部署 docker 的流程，以及 docker 常用的命令<br><br>Docker-Hub 管理镜像的方式和 github 管理代码的方式类似，你可在 <a href="https://hub.docker.com/" target="_blank" rel="external">Docker-Hub 网站</a>上面申请一个账号<br><br>便可以 push 自己创建的系统镜像，或是 search,pull 他人的系统镜像到本地了，十分方便。</p>
<hr>
<h1 id="u5B98_u7F51_u4E0A_u4E0B_u8F7D_docker"><a href="#u5B98_u7F51_u4E0A_u4E0B_u8F7D_docker" class="headerlink" title="官网上下载 docker"></a>官网上下载 docker</h1><p>打开终端，可以通过输入 docker 命令来检查当前系统中是否已经安装有 docker ，如果没有安装系统会显示出 </p>
<pre>
apt-get install docker.io 
</pre>

<p>的提示语句消息，按照提示输入命令来在 ubuntu 上面安装 docker<br>如果您想在 windows 上面部署 docker 环境，只需要到官网上面下载 docker-install.exe 文件即可，<br><br>该文件提供 windows 系统下面 docker 运行所需要的软件，包括 Virtual-Box ，Git 和 docker-hub 图形界面工具，<br><br>不过这里介绍的是基于 ubuntu 请打算在 windows 上面部署的同学绕行。  </p>
<hr>
<h1 id="docker__u4E2D_u7684_u955C_u50CF_u548C_u5BB9_u5668"><a href="#docker__u4E2D_u7684_u955C_u50CF_u548C_u5BB9_u5668" class="headerlink" title="docker 中的镜像和容器"></a>docker 中的镜像和容器</h1><p>在动手 pull 一个镜像之前，还要啰嗦一下，那就是对 docker 中的<b>镜像</b> ，<b>容器</b> 这两个名词的理解。<br><br>如果将镜像文件比作是 Java 编程语言中的类(文件)的话，那么容器便是基于 Java 类所实例化(new) 的一个对象实例。<br><br>镜像文件是不会被轻易改变的，它由唯一ID号码所标识，该 ID 号码和远程 pull 该镜像文件的镜像库中的文件 ID 号码保持一致。<br><br>而通过镜像文件实例化的容器一旦被创建，运行之后便是时刻处于变化状态。当然如果你如果想保存容器的当前状态的话，<br><br>也可以通过docker 提供的命令，将容器X(当前的状态)写入镜像文件中，这样再次通过镜像文件生成容器实例的时候，<br><br>该被生成的容器实例所处状态便和容器 X 是保持一致的。但是在这里也需要知道容器也是由不同的 ID 号码所唯一标识的，<br><br>就如同 Java 编程中每个类对象都由不同的 hashCode来标识一样。</p>
<hr>
<h1 id="u4F7F_u7528_docker"><a href="#u4F7F_u7528_docker" class="headerlink" title="使用 docker"></a>使用 docker</h1><p>在 docker 安装好了之后，输入 docker 命令之后会有很多参数提示信息，在这里介绍几个十分常用的命令:</p>
<h3 id="docker_-h"><a href="#docker_-h" class="headerlink" title="docker -h"></a>docker -h</h3><p>该命令用来显示 docker 的帮助选项</p>
<h3 id="docker_version"><a href="#docker_version" class="headerlink" title="docker version"></a>docker version</h3><p>用来显示当前 Docker 的版本信息，啰嗦一句， docker 在 1.8 版本之后才能够支持本地向 docker-hub 上面提交 docker 镜像文件。<br>所以有些时候查看 docker version 还是很有必要的(曾经使用 1.2 的 docker 提交镜像文件一个整下午失败的教训)</p>
<h3 id="docker_info"><a href="#docker_info" class="headerlink" title="docker info"></a>docker info</h3><p>该命令用来显示当前系统中 Docker 的信息，镜像文件和被创建的容器数目等信息</p>
<h3 id="docker_login"><a href="#docker_login" class="headerlink" title="docker login"></a>docker login</h3><p>该命令在你想 <a href="https://hub.docker.com/" target="_blank" rel="external">docker-hub</a> 上面注册信息之后，可以在命令行通过该命令远程登录， <br><br>如同 github 上面注册信息并添加ssh-key 之后通过 ssh 远程登录一样。</p>
<pre>
Username: kylin27
Password: *******************
Email: kylin27@outlook.com
</pre>

<p>你的登录信息存放在 .dockercfg 这个文件中</p>
<h3 id="docker_logout"><a href="#docker_logout" class="headerlink" title="docker logout"></a>docker logout</h3><p>注销当前登录的账号</p>
<h3 id="docker_search"><a href="#docker_search" class="headerlink" title="docker search"></a>docker search</h3><p>该命令用来在 docker-hub 上面寻找符合描述信息的 docker 镜像文件<br>比如我想搜索已经安装部署了 </p>
<ul>
<li>被其他用户收藏超过 10 次</li>
<li>列出信息的时候会显示了该镜像完整的描述信息</li>
<li>java8</li>
<li>并且能够自动化构建镜像</li>
<li>的docker 镜像的话可以</li>
</ul>
<pre>
docker search -s 10 --automated --no-trunc java8

# -s 10  搜查出被其他用户收藏(s short for stars) >= 10 次的 docker 镜像
# --automated 支持自动化构建镜像
# -- no-trunc 在显示被搜索的信息时，需要显示出完整的镜像描述信息
# java8 镜像描述信息
</pre>

<h3 id="docker_pull"><a href="#docker_pull" class="headerlink" title="docker pull"></a>docker pull</h3><p>将 docker-hub 中的镜像拉去(pull) 到本地镜像库</p>
<h3 id="docker_tag"><a href="#docker_tag" class="headerlink" title="docker tag"></a>docker tag</h3><p>为本地的某个镜像文件打标签，说到打标签就不得不啰嗦几句了，在 docker-hub 中通常将镜像文件按照标签来存放，<br>根据标签来存放镜像文件可以最大化的减少服务器端冗余的数据。 不过打标签是需要遵循一定的格式的:</p>
<pre>
docker tag username/image_name

## 其中 username 便是你使用 docker login 命令的时候使用的用户名
## image_name 便是你想为当前镜像文件起的名字
</pre>


<h3 id="docker_push"><a href="#docker_push" class="headerlink" title="docker push"></a>docker push</h3><p>便是将当前系统中的镜像文件’推送’到docker-hub 上面的命令，<br>推送之后，你便可以通过网页的 <a href="https://hub.docker.com/" target="_blank" rel="external">docker-hub</a> 登录自己的账户查看了(就是等同于 github 上面查看自己推送的代码一样)<br><br>推送之后，也就意味着这个镜像文件交个 docker-hub 来’托管’， 通过使用 docker search 命令也可以搜索得到的。<br>docker  push 命令推送镜像之前，最好(一定要)使用 docker tag 命令来为它打上标签</p>
<h3 id="docker_images"><a href="#docker_images" class="headerlink" title="docker images"></a>docker images</h3><p>列出本地镜像库中所有的镜像文件，当本地镜像库中镜像文件增多的时候，<br>推荐使用 <code>docker images [镜像文件起始名称]</code> 命令来查找(筛选)特定的镜像文件</p>
<h3 id="docker_ps"><a href="#docker_ps" class="headerlink" title="docker ps"></a>docker ps</h3><p>这个命令用来显示当前系统中所有运行的容器</p>
<h3 id="docker_rmi"><a href="#docker_rmi" class="headerlink" title="docker rmi"></a>docker rmi</h3><p>这个命令用来删除本地镜像文件</p>
<h3 id="docker_rm"><a href="#docker_rm" class="headerlink" title="docker rm"></a>docker rm</h3><p>删除本地容器对象，镜像文件就像是母鸡，删了就不能生蛋(容器)了，但蛋砸了(容器删了)只要是母鸡(生成该容器的镜像文件)还在，一切都好说。<br><br>如果当前容器的状态没有同步到镜像文件中，那… 就当我啥也没说好了.</p>
<h3 id="docker__5Bstart_7C_stop__7C_restart_5D"><a href="#docker__5Bstart_7C_stop__7C_restart_5D" class="headerlink" title="docker [start| stop | restart]"></a>docker [start| stop | restart]</h3><p>docker 容器运行系列命令，分别是启动，停止，重启一个容器</p>
<h3 id="docker_pause"><a href="#docker_pause" class="headerlink" title="docker pause"></a>docker pause</h3><p>暂停某个容器中的所有进程，但是该docker容器的进程并不停止 停止docker容器中的进程 != 杀死 docker 容器</p>
<h3 id="docker_unpause"><a href="#docker_unpause" class="headerlink" title="docker unpause"></a>docker unpause</h3><p>将 docker 容器中被暂停的进程重新恢复运行</p>
<h3 id="docker_kill"><a href="#docker_kill" class="headerlink" title="docker kill"></a>docker kill</h3><p>杀死 docker 某个容器进程，杀死 != 移除</p>
<h3 id="docker_save"><a href="#docker_save" class="headerlink" title="docker save"></a>docker save</h3><p>将镜像文件进行归档保存,后接参数 -o (output file) 用来指定归档文件的名称<br>第一个参数是生成归档的文件名称，<br><br>第二个参数是本地镜像文件名称，这里的冒号后面对应是为同一个镜像文件的不同变动所加上的标签 ;<br><br>我通常是按照对当前镜像文件作出的改变，或者是镜像文件生成的日期来添加标签(好记…)<br>同时归档文件还可以使用 .tag.gz ; .tgz, bzip 等等多种压缩文件类型 </p>
<pre>
docker save -o kylin27_java8.tar kylin27/ubuntu:java8
</pre>

<h3 id="docker_load"><a href="#docker_load" class="headerlink" title="docker load"></a>docker load</h3><p>将归档(docker save 生成的 .tar 文件之后)的docker 镜像文件，重新生成 docker 经常文件(save 的逆向操作)<br>后接参数 -i (input file)</p>
<pre>
docker load -i kylin27_java8.tar
</pre>

<h3 id="docker_export"><a href="#docker_export" class="headerlink" title="docker export"></a>docker export</h3><p>刚刚介绍的拿对是 <b>镜像文件 &lt;=&gt; 归档文件</b>的相互转换， 接下来的这两个命令便是<b>容器 =&gt; 归档文件 ; 归档文件 =&gt; 镜像</b>的相互转换。<br>docker export -o 命令是将当前的容器进行归档，</p>
<pre>
docker export -o kylin27_container_java8.tar 30484q39as30
</pre> 

<p>上述的命令是将 ID 号码为 30484q39as30 的容器归档生成名为 kylin27_container_java8.tar 的文件</p>
<h3 id="docker_import"><a href="#docker_import" class="headerlink" title="docker import"></a>docker import</h3><p>将容器归档文件生成镜像文件</p>
<pre>
cat ./kylin27_container_java8.jar | sudo docker import - kylin27_ubuntu:java8
</pre>

<p>上述的命令是用来将数据信息从归档文件 kylin27_java8.jar 中读出来，然后调用 docker import 命令生成名为 kylin27_ubuntu:java8 的镜像文件</p>
<h3 id="docker_commit"><a href="#docker_commit" class="headerlink" title="docker commit"></a>docker commit</h3><p>将当前处于运行状态的容器中所有被变动的状态同步给镜像文件，也就是将这个容器进行模板化，将容器中所有的信息写入(更新)到<br>镜像文件中(该镜像文件既可以是原来的镜像文件，也可以写入到一个新的镜像文件中)</p>
<pre>
docker commit [容器ID] [要被更新的镜像文件名称|新创建的镜像文件名称]
</pre>


<h3 id="docker_inspect"><a href="#docker_inspect" class="headerlink" title="docker inspect"></a>docker inspect</h3><p>在刚才介绍的命令中，比较一般的登录到运行容器中的方法是 docker run 后接登录之后执行的程序，<br><br>在上述命令中介绍的是一登录容器边启动它的命令控制台的交互程序，还有一种方式是先使用 run 方法来登录然后修改容器的 IP 地址，<br><br>在通过 ssh 的方式来登录。 不过官方推荐的方式是，使用 docker inspect + 容器 ID 号码来提取正处于运行状态的容器 PID 号码<br><br>(对的就是容器的进程号)， 然后通过  nsenter  这个程序来直接切入到容器进程中； 我们接下来就介绍这种方法:<br><br>nsenter  在 Ubuntu-14.4 和它之前的版本均不支持，如果您的 Ubuntu 版本要小于等于 14.4 那么通过下面的命令来安装(更新)</p>
<pre>
cd /tmp
curl https://www.kernel.org/pub/linux/utils/util-linux/v2.24/util-linux-2.24.tar.gz | tar -zxf-cd util-linux-2.24./configure --without-ncursesmake nsentercp nsenter /usr/local/bin
</pre>

<p>不得不说，有人曾经很详细的了解 docker 用来存放镜像和容器的底层文件，发现 docker 底层是通过使用 json-schema 格式的文件来存放镜像和容器<br> 所处的状态的，而当前所介绍的这个 docker inspect 命令便是抽取 docker 容器对应的 json-schema 格式的文件内容，而后面的通过参数来指定<br> 需要获取的是底层文件中的哪种属性信息字段<br>输入上述命令之后，便可以获取当前运行容器的进程 PID 号码</p>
<pre>
$docker inspect --format param  容器 ID 号
</pre>
<b>上述的param 使用冒号中括号中括号.State.PID 中括号中括号冒号 来替代，我的博客格式显示有点问题，没办法直接表示</b>

输入上述命令之后，便可以获取当前运行容器的进程 PID 号码

<pre>
$nsenter --target $PID --mount --uts --ipc --net --pid 
</pre>

<p>上面的 $PID  使用输入 docker inspect 命令之后显示出来的数据结果来替代</p>
<hr>
<h1 id="docker__u547D_u4EE4_u4F7F_u7528_u6848_u4F8B"><a href="#docker__u547D_u4EE4_u4F7F_u7528_u6848_u4F8B" class="headerlink" title="docker 命令使用案例"></a>docker 命令使用案例</h1><p>接下来通过案例的方式来系统学习一下 ubuntu 下面 docker 的使用方法，在案例中，我们要</p>
<ul>
<li><p>下载 ubuntu 的镜像文件</p>
<pre>
$docker pull ubuntu:14.04
output message :
14.04: Pulling from ubuntu
f15ce52fc004: Downloading 24.85 MB/65.68 MB
f15ce52fc004: Downloading  25.4 MB/65.68 MB
f15ce52fc004: Downloading 56.75 MB/65.68 MB
8693db7e8a00: Download complete
</pre>
</li>
<li><p>显示当前系统中所有 docker 镜像文件</p>
<pre>
$docker images 
output message :
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
ubuntu              14.04               8693db7e8a00        3 weeks ago         187.9 MB
</pre>
</li>
<li><p>通过镜像文件生成容器并登录</p>
<pre>
$docker run -i -t ubuntu14.04/bin/bash
output message :
root@b4bfcdde7b31:/#    // 这就进入了运行的 ubuntu:14.04 的容器中了 ; 退出的话直接在命令行中输入 exit 即可
</pre>
</li>
<li><p>登录容器之后，安装一个 wget 软件</p>
<pre>
root@b4bfcdde7b31:/# apt-get install wget 
</pre>
</li>
<li><p>待到软件安装成功之后，将容器当前状态更新到新创建的镜像文件中</p>
</li>
<li>不过首先应该获取到该容器的 ID 号码，打开一个新的 ssh 远程连接/终端窗口输入查看当前系统中所有容器和其ID号码<pre>
$docker ps 
output message :
docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
b4bfcdde7b31        ubuntu:14.04        "/bin/bash"         4 minutes ago       Up 4 minutes                            desperate_poitras   
// b4bfcdde7b31  这个便是容器的 ID 号码，用于在系统中唯一标识容器
</pre>


</li>
</ul>
<ul>
<li><p>生成该<b>容器</b>的归档文件</p>
<pre>
$docker export -o kylin27_container_wget.tar.gz b4bfcdde7b31 
# 等待之后，便会在当前路径下面找到名为 kylin27_container_wget.tar.gz 的归档文件
</pre>
</li>
<li><p>生成该容器的镜像文件<br><pre><br>$docker commit b4bfcdde7b31 ubuntu_14:wget<br>// 冒号后面的是为镜像文件创建的标签，而冒号前面是该镜像文件对应镜像库的名称</pre></p>
</li>
</ul>
<p></p>
<ul>
<li><p>为该镜像文件打标签<br>在将镜像文件提交到 docker-hub 上面的时候需要注意两点 1. 确保成功 login 2. 确保 docker 镜像文件所打的标签符合 docker-hub 格式<br>必定如果你用过 github 的话(没用过也不会看到这篇搭建在 github 上面的博客)应该熟悉 github 上面的 repository 的命名和路径规则<br> 通常是用户名+资源库名称，道理放到 docker-hub 上面也是一样的。</p>
<pre>
docker tag ubuntu_14:wget kylin27/ubuntu14:wget
</pre>

<p>再次输入命令 docker images 会看到如下信息</p>
<pre>
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
ubuntu_14           wget                44552cea1d79        5 minutes ago       187.9 MB
kylin27/ubuntu14    wget                44552cea1d79        5 minutes ago       187.9 MB
ubuntu              14.04               8693db7e8a00        3 weeks ago         187.9 MB
</pre>

<p>看到ubuntu_14 和 kylin27/ubuntu14 这两个镜像文件虽然镜像库名称不同，但是 IMAGE ID 却是相同的，这就是方便区分标识，但却最大程度上减少冗余文件的存储的思想所在。</p>
</li>
<li><p>为该<b>镜像</b>创建文档文件</p>
<pre>
$docker save -o kylin27.tar ubuntu_14:wget
</pre>

<p>随后便可以在当前目录下面看到名为 kylin27.tar 的归档文件</p>
</li>
<li><p>将该镜像文件推送到 docker-hub 上面 <b>在推送镜像文件之前，需要先把系统中生成该镜像文件的容器给停止(血与泪的教训) </b></p>
<pre>
$docker stop b4bfcdde7b31
$docker push kylin27/ubuntu14:wget
output message:
The push refers to a repository [kylin27/ubuntu] (len: 1)
44552cea1d79: Image already exists 
8693db7e8a00: Image successfully pushed 
a4c5be5b6e59: Image successfully pushed 
c4fae638e7ce: Image successfully pushed 
f15ce52fc004: Image successfully pushed 
Digest: sha256:09dd6e67f2c8ec9a0a9e21f4e34f415083dcd29a96e156b5d36fbdd4295f5c2f
</pre>

</li>
</ul>
<p>成功推送信息之后，到自己的 <a href="https://hub.docker.com/r/kylin27/ubuntu/" target="_blank" rel="external">docker-hub</a> 上便可以看到咯~<br>  在页面右边的显示信息便是该镜像文件 pull 的路径，如果你对这个镜像文件感兴趣的话便可以通过该信息将镜像 pull 到本地</p>
<ul>
<li>再来介绍一个 docker 中实用的批量删除 none 镜像文件的命令<br>在频繁创建删除 docker 镜像文件之后便会生成很多名为 none 的镜像文件，在这里可以通过下面的命令将所有无用的 none 镜像文件删除。<pre>
$docker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker stop
$docker ps -a | grep "Exited" | awk '{print $1 }'|xargs docker rm
$docker images|grep none|awk '{print $3 }'|xargs docker rmi
</pre>

</li>
</ul>
<p>end</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/13/2016.2.13.docker_install/" data-id="cil3ik2v1002lh4im5uhrlduv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux/">Linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ubuntu/">Ubuntu</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.12.scala_BiMap" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/12/2016.2.12.scala_BiMap/" class="article-date">
  <time datetime="2016-02-11T16:00:00.000Z" itemprop="datePublished">2016-02-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/12/2016.2.12.scala_BiMap/">google guava&#39;s BiMap</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:<br><br>google guava 中提供的一种非常有用的数据结构，双向 Map。是的，你没有听错，就是相比于普通仅能够提供 key 到 value 映射的 Map ，双向Map既能够提供 key 到 value 的映射，有能够提供 value 到 key 的映射。<br>这在某些特定场合是非常有用的，那么接下来简单介绍一下 BiMap 的使用方法。</p>
<hr>
<h1 id="BiMap__u6240_u652F_u6301_u7684_u65B9_u6CD5"><a href="#BiMap__u6240_u652F_u6301_u7684_u65B9_u6CD5" class="headerlink" title="BiMap 所支持的方法"></a>BiMap<k,v> 所支持的方法</k,v></h1><h2 id="V_forcePut_28K_key_2C_V_value_29"><a href="#V_forcePut_28K_key_2C_V_value_29" class="headerlink" title="V forcePut(K key, V value)"></a>V forcePut(K key, V value)</h2><ul>
<li>方法介绍: 该方法用来强制执行 BiMap<k,v> 所继承的 Map<k,v> put() 方法. 也就是说如果 map 中有<br>“a-key”-&gt;”a-value” 的话，在执行 biMap.forcePut(“a-key”,”a-value2”) “a-value2” 会强制取代 “a-value” 的位置</k,v></k,v></li>
</ul>
<h2 id="BiMap_inverse"><a href="#BiMap_inverse" class="headerlink" title="BiMap inverse"></a>BiMap<v,k> inverse</v,k></h2><ul>
<li>方法介绍: 该方法会将当前的<k,v> 转换成 <v,k> </v,k></k,v></li>
</ul>
<h2 id="V_put_28K_key__2C_V_value_29"><a href="#V_put_28K_key__2C_V_value_29" class="headerlink" title="V put(K key , V value)"></a>V put(K key , V value)</h2><ul>
<li>方法介绍: 该方法用来向数据结构中放入 key-value 键值对<h2 id="void_putAll_28Map_26lt_3B_uFF1F_extends_K_2C__3F_extends_V_26gt_3B_map__29"><a href="#void_putAll_28Map_26lt_3B_uFF1F_extends_K_2C__3F_extends_V_26gt_3B_map__29" class="headerlink" title="void putAll(Map&lt;？ extends K, ? extends V&gt; map )"></a>void putAll(Map&lt;？ extends K, ? extends V&gt; map )</h2></li>
<li>该方法用来将 Map<k1,v1> 类型的一次性全部放入到当前 BiMap<k,v> 中，不过值得注意的是 K1, V1 必须要是 K,V 类型或使其子类<h2 id="Set_values_28_29"><a href="#Set_values_28_29" class="headerlink" title="Set values()"></a>Set<v> values()</v></h2></k,v></k1,v1></li>
<li>该方法用以集合的方式来获得 BiMap 的值集合</li>
</ul>
<hr>
<ul>
<li>下面通过一个例子来介绍一下如何使用 BiMap，通过一个 Seq 类型的字符串 List 生成 key-value 对字典，</li>
<li>然后将字典进行反转操作，将原来的 k-v 编程 v-k 映射map </li>
</ul>
<pre>
object MatchPatternTester extends App{

    // 将传入的 Seqp[String] 通过 zipWithIndex.toMap 的方式
    // 转换成 Map<string,int> 类型，然后通过调用 ImmutableBiMap 中的 putAll 方法
    // 将其传入到 ImmutableBiMap 中，然后调用它的 build 方法生成 BiMap<string,int> 

    def getMapFromSeq(dict: Seq[String]): Unit ={
        val kTv = ImmutableBiMap.builder[String,Int]()
              .putAll(dict.zipWithIndex.toMap[String,Int])
              .build()

    // 获取 BiMap 的 key 集合
    val values = kTv.keySet()

    // 通过获取的 key 集合遍历 BiMap<string,int> 中的每个 key-value 元素对
    values.foreach( (x: String ) => println("key " + x +" value "+ kTv(x)))

    // 调用 BiMap 的 inverse 方法来将 BiMap<string,int> 转换成 BiMap<int,string>    
    val inverseMap = kTv.inverse()

    // 获取反转之后的 key 集合
    val values2 = inverseMap.keySet()
    // 在获取 key 集合之后遍历反转之后的 BiMap<int,string> 
    values2.foreach((k: Int ) => println("key " +k + " value "+ inverseMap(k)))

  }

  // 创建传入参数(Seq[String])
  val listInput = List[String]("aimer","aimer","kylin","kokia","rurutia","kylin")

  getMapFromSeq(listInput)

}
</int,string></int,string></string,int></string,int></string,int></string,int></pre>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/12/2016.2.12.scala_BiMap/" data-id="cil3ik2lc0000h4imr6xqz97o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/datastructure/">datastructure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scala/">scala</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.5.scala_theory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/11/2016.2.5.scala_theory/" class="article-date">
  <time datetime="2016-02-10T16:00:00.000Z" itemprop="datePublished">2016-02-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/11/2016.2.5.scala_theory/">scala编程相关知识1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description:<br>这篇博客中记录一下 scala 编程语言中的知识点</p>
<hr>
<h1 id="case_class__u5728_scala__u4E2D_u7684_u4F7F_u7528_u65B9_u6CD5"><a href="#case_class__u5728_scala__u4E2D_u7684_u4F7F_u7528_u65B9_u6CD5" class="headerlink" title="case class 在 scala 中的使用方法"></a>case class 在 scala 中的使用方法</h1><p> case class 和 java 中所定义的 class 二者类似</p>
<ul>
<li>在创建 case class 对象实例的时候，可以不用在实例前面加上 new 关键字</li>
</ul>
<pre>
case class apple(name:String)
class banana(color:String)

val app = apple("i am a apple — —b")
val ban = new banana("i am yellow — —||")
</pre>

<ul>
<li><p>case class 创建的类对象实例调用 .toString 方法时显示出来的字体更漂亮<br>case class 实例会将 ‘case class 名称(里面是成员变量名称)’ 显示出来<br>class 的 .toString 方法会显示类似 java 语言直接打 Object 象信息的数据<br>如果你想通过打印的方式来快速获取类对象中的成员数据信息的话，推荐使用 case class</p>
</li>
<li><p>case class 默认实现了 equals 和 hashCode 两个方法，所以 case class 实例化的对象可直接调用这两个方法</p>
</li>
<li><p>case class 实现了(extends) Serializable ，可以对 case class 对象执行序列化操作</p>
</li>
<li>在声明 case class 的时候，传入的构造参数均是 public 的可以直接通过 实例名称.构造函数参数名称<br>来访问</li>
</ul>
<pre>
case class Document(docId: String, body: String="", label: Set[String] = Set.empty, integerLabel: Int)
其中 body: String="" 这种赋值方式是默认赋值，如果调用者没有为该参数指定参数数值的话，就会使用默认的赋值。
如果调用者为该参数指定特定数值的话，该指定的特定数值便会替代该指定默认参数数值
但是如果最后一个参数为必须传入数值的参数类型的话，中间的参数数值是必须要给定的

1. val doc1 = Document("id1",2)
   println(doc1.toString) // 将会出错
2. val doc2 = Document("id2","doc2",Set("abc","eft")
   println(doc1.label)  // output Set(abc,eft)   
</pre>

<ul>
<li>case class 对象实例支持模式匹配，这是 scala 为何要提出 case class 这一类型的原因</li>
</ul>
<pre>
abstract  class methodX
case class test1(n: Int) extends methodX
case class test2(a: Int, b: Int) extends methodX

object MatchPatternTester extends App{

  def matchTester(term: methodX ){
    term match{
      case test1(n) =>
        println("this is test1" +n)
      case test2(a,b) =>
        println("this is test2 a , b"+a +" " +b)
    }
  }

 val x1 = test1(1027)

 val x1Result =matchTester(x1)

 val x2 = test2(10,72)
 val x2Result = matchTester(x2)

}
</pre>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/11/2016.2.5.scala_theory/" data-id="cil3ik2sp000vh4imx8gi8i5d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/programming-theory/">programming-theory</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scala/">scala</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2016.2.5.search_engine_theory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/06/2016.2.5.search_engine_theory/" class="article-date">
  <time datetime="2016-02-05T16:00:00.000Z" itemprop="datePublished">2016-02-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/06/2016.2.5.search_engine_theory/">搜索引擎知识点整理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Description: 这篇博客简单介绍一下搜索引擎中的基础知识和原理。<br><br>由于在开发 github 上的 <a href="https://github.com/Kylin27/StackExchangeRecommener/" target="_blank" rel="external">StackExchangeRecommenderSystem</a> 时候会用到 lucene，<br>所以在这里先来复习一下搜索引擎中的基础知识和算法。</p>
<hr>
<h1 id="u7D22_u5F15_u7684_u57FA_u7840_u77E5_u8BC6"><a href="#u7D22_u5F15_u7684_u57FA_u7840_u77E5_u8BC6" class="headerlink" title="索引的基础知识"></a>索引的基础知识</h1><p>索引是在程序员的世界是常常被提起的名词，例如，在数据库中，在编程的时候为高级复杂的数据结构以及<br>对网页所创建索引，来提高程序的查询效率。<br>索引在日常生活中也很常见:字典目录中某个词语后面标识了出现该词的页码。<br>下面我们来一起学习一下，关于索引常见的词汇:</p>
<ul>
<li>文档(Document): 索引所标定的’目标对象’: 是数据库索引，那么文档便是数据表中的某条记录;<br>如果是对网页创建的’倒排索引’(索引的一种类型)，那么文档便是网页的页面； 这个’目标对象’<br>还可以是某种具体的文件，例如 word，PDF文档</li>
<li>文档集合 (Document Collection): 就是上述’文档’构成的集合</li>
<li>文档编号(Document ID): 在搜索引擎内部为每个文档赋予的唯一标识，可以在文档集合中唯一标识一个文档</li>
<li>单词编号(Word ID): 用来唯一标识某个单词</li>
<li>倒排索引(Inverted Index): 普通的索引是为某个文档创建索引出在该文档中某个单词，<br>而倒排索引则是以单词为主题，通过单词来索引出出现该单词出现的文件； 倒排索引由两部分组成<br>{单词词典,和出现该单词的文档集合}</li>
<li>单词词典(Lexicon): 搜索引擎通中的索引单位是单词，单词词典是在所有文档集合中出现过的单词所构成的集合；<br>而在单词词典中的每条索引项中记录的信息有{单词信息，单词所指向出现该单词的文章集合-倒排列表} </li>
<li>倒排列表(PostingList): 倒排列表指的是，出现过某个单词的所有文档所构成的列表和该单词在该文档中出现的<br> 位置信息； 倒排列表中的每条记录我们可以将其称作是倒排项(Posting).</li>
<li><p>倒排文件(Inverted File): 倒排文件是存储倒排索引的物理文件。我们都已经知道了倒排索引由两部分组成，<br>分别是，单词词典和倒排列表. 在此基础上，存放倒排列表的文件就叫做倒排文件。   </p>
<hr>
<h2 id="u5012_u6392_u7D22_u5F15_u5C0F_u4F8B_u5B50"><a href="#u5012_u6392_u7D22_u5F15_u5C0F_u4F8B_u5B50" class="headerlink" title="倒排索引小例子"></a>倒排索引小例子</h2><p>比如那今天的知乎日报新闻来举例</p>
<pre>
文章编号            文章标题
1                    如何自己制定健身训练计划？
2                    女生怎么健身锻炼好身材？
3                    减肥对外貌的改变有多大？
4                    健身教练有哪些内幕？
5                   女生如何锻炼减肥既简单有健康？
</pre>
<pre>
单词 ID         单词        倒排列表
  1.            自己          {1}
  2.            女生          {2,5}
  3.            减肥            {3,5}
  4.            健身          {1,2}
  5.            教练          {4}
  6.            简单          {5}
  7.            训练          {1}
  8.            外貌          {3}
  9.            改变          {3}
  10.            哪些          {4}    
  11.         内幕          {5}
  12.            锻造          {2,5}
  13.            身材          {2}    
  14.            训练          {1}
  15.            计划          {1}
 </pre>

</li>
</ul>
<p>当然，我们也为了让索引列表更细致的记录索引文件的信息来添加上某个词语出现的频率信息，TF 便是用来描述词语在某个文章中出现的次数的. 例如 ‘女生’ 这个词语在文章 2，5 均出现过，并且出现 1 次<br>便可以记成 女生 {2;1,5;1} 这样子。更加细致的记录方式是，将这个单词出现的位置也记录下来：<br><br>例如 ‘女生’这个单词在文章2,5中出现的位置分别是第 1 个位置，就写成如下的格式<br>女生 { (2;1;<1>),(5;1;<1>) }</1></1></p>
<hr>
<h1 id="u5355_u8BCD_u8BCD_u5178__28Lexicon_29"><a href="#u5355_u8BCD_u8BCD_u5178__28Lexicon_29" class="headerlink" title="单词词典 (Lexicon)"></a>单词词典 (Lexicon)</h1><p>单词词典存放了在文档集合中出现过的所有单词的相关信息的同时也记录了该单词集合中的每个单词<br>所映射到的倒排列表在倒排文件中的位置信息。</p>
<p>可以试想一下，如果需要创建索引的文档集合十分的巨大，那么随之提出出来的单词词典中所存放的单词数量<br>也是十分庞大的。在数据结构课程中我们已经学习过，如果要快速的定位某个单词(键值)的话可以借助于<br>哈希链表或是树形词典这类的数据结构。 </p>
<h2 id="u54C8_u5E0C_u52A0_u94FE_u8868_-__u5355_u8BCD_u8BCD_u5178"><a href="#u54C8_u5E0C_u52A0_u94FE_u8868_-__u5355_u8BCD_u8BCD_u5178" class="headerlink" title="哈希加链表 - 单词词典"></a>哈希加链表 - 单词词典</h2><p>   哈希加链表是处理哈希表冲突的一种解决方法，哈希表有随之配套的 hash 散列函数，会为每个输入的<br>   key 键生成’唯一’标定该key 对应 value 的标识，但是如果 hash 散列函数选取的不当的话，便会造成<br>   不同的 key 生成了重复的标识； 这就是所谓的’冲突’的发生，处理’冲突’有着不同的方法，<br>   加链表就是在发生冲突的 key 的后面开辟一块空间存放后来的 key ; 待到查找的时候，通过 hash 散列函数<br>   找到该 hash 生成数值指定的链表头，沿着链表继续寻找就可以了。</p>
<h2 id="u6811_u5F62_u7ED3_u6784_-__u5355_u8BCD_u8BCD_u5178"><a href="#u6811_u5F62_u7ED3_u6784_-__u5355_u8BCD_u8BCD_u5178" class="headerlink" title="树形结构 - 单词词典"></a>树形结构 - 单词词典</h2><p>   前缀树和后缀树都是可以做单词词典很好的数据结构</p>
<hr>
<h1 id="u5012_u6392_u5217_u8868"><a href="#u5012_u6392_u5217_u8868" class="headerlink" title="倒排列表"></a>倒排列表</h1><p>  在前面我们提到过了，倒排列表中的基本构成单元倒排索引项中包含字段有:<br>  {单词出现的文档的唯一编号,单词出现频率,&lt;单词在文档中的位置1,位置2,位置3…&gt;}<br>  但是在实际的应用中为了尽量节省内存，通常会使用文档编号的差值来取代文章的唯一编号。</p>
<hr>
<h1 id="u5EFA_u7ACB_u7D22_u5F15"><a href="#u5EFA_u7ACB_u7D22_u5F15" class="headerlink" title="建立索引"></a>建立索引</h1><p>建立索引有着不同的方法,同时索引也分为动态索引和静态索引，其中静态索引是生成索引之后在修改文档集合中的<br>文档之后，不能自动的更新之前索引文件 ； 而动态索引则是生成索引之后，修改文档集合中的文件内容之后<br>会随之自动的更新文档文件。</p>
<h2 id="u9759_u6001_u7D22_u5F15"><a href="#u9759_u6001_u7D22_u5F15" class="headerlink" title="静态索引"></a>静态索引</h2><h3 id="u4E24_u904D_u6587_u6863_u904D_u5386_u6CD5"><a href="#u4E24_u904D_u6587_u6863_u904D_u5386_u6CD5" class="headerlink" title="两遍文档遍历法"></a>两遍文档遍历法</h3><p>两遍文档遍历法在创建索引的时候需要对文档集合执行两遍扫描，在创建索引的时候仅需要内存即可，整个过程无需磁盘参与。</p>
<ul>
<li>首次扫描:<br>算出为该文档集合创建的索引所需的内存容量大小:搜集文档集合包含文档个数 N ，文档集合中不重复单词总数 M, 每个单词在多少个文档中出现 DF. 将所有单词的 DF 数值进行加和便是建立最终索引所需要的内存大小。</li>
<li><p>第二次扫描:</p>
<pre><code>首次扫描已经确定了文档集合中的每个单词的 DF信息，在第二次扫描的时候，为每个单词的 DF 信息
</code></pre><p>分配内存空间，并使用指针将单词集合与单词的 DF 信息将连接即可，也就是简历每个单词的倒排列表信息；<br>但是通过上面的陈述可知，在单词倒排列表中的倒排索引项仅仅包含单词 DF信息还是不够的；对文档 ID 或是文档 ID 偏移量的计算以及单词在文档中出现位移和出现次数等这些信息都可以在第二次扫描的时候来完成。<br>  等到两遍扫描结束之后，将内存中创建的倒排列表和单词词典信息写入到磁盘中就完成了索引的创建了。</p>
</li>
<li><p>对两遍文档遍历法的评估: 因为全程使用的是内存无需磁盘的参与，所以连通文档集合和生成的倒排列表等数据信息均需要存放到内存中，这需要内存足够大，或者是仅仅适用于创建文档集合规模较小的索引。同时，需要对文档进行两次扫描，比较耗时在速度上并不占优势。      </p>
<h3 id="u6392_u5E8F_u6CD5"><a href="#u6392_u5E8F_u6CD5" class="headerlink" title="排序法"></a>排序法</h3><p>排序法为文档集合创建索引是为了弥补两遍遍历法建立索引过程中，对内存消耗大这一缺点提出的。两边遍历索引生成方法使用内存的大小是不固定的，如果文档集合大内存开辟就会大一些，相反便会小一些。而排序法无论文档集合如何，其所需要的内存大小均是固定分配的。开辟的内存空间主要用来存放词典信息和索引的中间结果。<br>每当中间结果将内存吃空的时候，便会统一将内存中的中间数据写入到磁盘中。遵循上述倒排索引中所介绍的两部分的结构-单词词典,倒排列表(倒排列表的组成单元是倒排索引项)，在整个的排序法创建文件集合索引的过程中，单词词典始终是作为常驻内存的数据结构的。</p>
</li>
<li>读取文档，对文档进行编号，每个文档为其创建唯一的标识 ID 号码</li>
<li><p>解析文档，每当在文档中遇到新单词，</p>
<pre>
{ 
查看该单词在单词词典中是否有记录 
1. 有记录，获取该单词在词典中的 ID 号码
2. 单词词典中没有记录该单词，为该单词创建全词典唯一的 ID 号码，然后将其收录到单词词典中
}
</pre>
</li>
<li><p>在对当前文档完成了读取和解析之后，便能够为当前文档中出现的每个单词均创建包含着如下信息</p>
</li>
</ul>
<pre>
 (单词ID,文档ID,单词频率)
</pre>

<p>上述三元组便可以作为倒排索引列表中的索引项了，将该三元组索引项集合追加到用来存放中间处理结果的大小固定的内存缓冲区中。然后便可以开始处理下一个文档了。<br></p>
<ul>
<li>在内存缓冲区被占满之前需要将缓冲区中的数据写入到磁盘临时文件中去，不过在写入之前需要对内存中的三元组序列执行排序操作； 首先按照单词 ID 进行非递减，然后按照文档 ID 进行非递减排序。由于内存中存放的中间结果并不一定全都是同一个文件生成的中间信息，所以会有单词ID 相同但是文档ID不同的情况，这种情况按照文档ID非递减的规则进行排序。<b>PS: 在上述的全部过程中，单词词典是常驻内存的</b> </li>
<li>每次执行向磁盘中写入中间缓存文件操作均是写入一个新的缓存文件，而不是在之前的缓存文件中执行追加。在对所文档集合中的每个文档均读取解析之后，剩下的工作便是合并临时写入磁盘的所有的中间文件了。由于写入磁盘之前在内存中执行了先按单词ID然后文章ID进行排序的操作，所以在合并的时候，只要首先将所有中间文件中单词ID相同的三元组合并为一个数组(由三元组元素构成的有序序列)，而所有的数组组合起来便是该文件的倒排列表了。接下来只要将倒排列表中的内容写入到文件中即可。而这个文件便是所谓的索引文件了。      </li>
<li>对排序法的评估: 在排序法创建文档集合索引的过程中，单词词典作为常驻内存数据结构并不会被写入到磁盘的中间临时文件中且大小也随着解析文档个数的增多而变大，同时排序法中分配的内存大小是固定的，所以当单词词典大小变大之后，每次用来缓存三元组的个数也会随之减少，如果单词词典继续增大会无法缓存解析文件而生成的三元组，这样便会频繁的执行写入操作,从而导致程序整体性能的下降。</li>
</ul>
<h3 id="u5F52_u5E76_u6CD5"><a href="#u5F52_u5E76_u6CD5" class="headerlink" title="归并法"></a>归并法</h3><p>归并法是为了弥补排序法中，单词词典常驻内存耗空分配的固定内存这一缺陷而提出的。归并法的特点是在每次执行三元组数据信息写入的同时也会将单词词典信息写入到中间临时文件中。这样便可以保证为程序分配固定大小的内存会全部用于后续索引的创建。</p>
<ul>
<li>归并法的执行过程和排序法大部分相同，不同之处之一是在写入中间缓存文件中是将 {单词词典，三元组集合} 写入到中间缓存文件中<pre><code>之二是在文档集合中的全部文档完成解析之后，将所有生成的临时文件进行合并的时候，每个临时文件中存放的是最终倒排列表的一部分；
而最后的合并操作便是将所有的部分倒排列表合并成一个完成的倒排列表。
</code></pre></li>
</ul>
<h2 id="u5206_u5E03_u5F0F_u7D22_u5F15"><a href="#u5206_u5E03_u5F0F_u7D22_u5F15" class="headerlink" title="分布式索引"></a>分布式索引</h2><p>分布式索引和数据库中的’分片’ 技术有些类似，数据库的’分片’ 技术是通过将一张大数据库表中的信息按照表中的某个属性字段<br>中的不同值/或是范围分割成许多个来自于该大数据表的’子表’； 常用作’分片’的属性有地域和时间 ；<br>而分布式索引技术则是将文档集合按照文档或者是单词来对索引进行划分。</p>
<h3 id="u6309_u7167_u6587_u6863_u6765_u5212_u5206_u7D22_u5F15"><a href="#u6309_u7167_u6587_u6863_u6765_u5212_u5206_u7D22_u5F15" class="headerlink" title="按照文档来划分索引"></a>按照文档来划分索引</h3><p>将大的文档集合划分成分布于不同机器上的文档子集，为每个文档自己创建各自的索引。<br>在执行查询的时候，会在每个机器上面执行查询，并把来自于每个子集的查询结果进行合并生成最终查询结果</p>
<h3 id="u6309_u7167_u5355_u8BCD_u6765_u5212_u5206_u7D22_u5F15"><a href="#u6309_u7167_u5355_u8BCD_u6765_u5212_u5206_u7D22_u5F15" class="headerlink" title="按照单词来划分索引"></a>按照单词来划分索引</h3><p>在创建按照单词划分的倒排索引的时候，划分发生在合并中间缓存文件生成最终索引文件的时候。<br>每当将来自于所有中间缓存文件中的同一单词ID的三元组合并之后，将该三元组集合+单词发送到某台主机上面。<br>便完成了按照该单词对索引进行’分片’的操作。<br>在实际的应用场景中，按照文档来进行索引的划分这种方法比较常使用，而按照单词的划分仅仅在特定场合下使用。<br>因为按照单词来划分索引的可扩展性、均衡负载和容错性都不是很好。</p>
<h1 id="u67E5_u8BE2_u5904_u7406"><a href="#u67E5_u8BE2_u5904_u7406" class="headerlink" title="查询处理"></a>查询处理</h1><h2 id="u4E00_u6B21_u4E00_u4E2A_u5355_u8BCD_u7684_u67E5_u8BE2_u5904_u7406"><a href="#u4E00_u6B21_u4E00_u4E2A_u5355_u8BCD_u7684_u67E5_u8BE2_u5904_u7406" class="headerlink" title="一次一个单词的查询处理"></a>一次一个单词的查询处理</h2><p>将用户查询语句执行清洗(我通常把去掉语句中无用符号和去掉停用词的操作叫做’清洗’…好记),<br>然后执行分词操作将语句分成多个词语组成集合，获取每个词语的倒排列表，然后计算每个词语与倒排列表中的<br>每一个文件的相似度，计算相似度之后，如果有文档重复的(两个不同词语倒排索引到同一个文档)，那么将重复的文档<br>得分进行累加；最后将得出得分最高的 K 个文档(通过优先队列进行存放)作为查询结果进行返回即可</p>
<h2 id="u4E00_u6B21_u4E00_u4E2A_u6587_u6863_u7684_u67E5_u8BE2_u5904_u7406"><a href="#u4E00_u6B21_u4E00_u4E2A_u6587_u6863_u7684_u67E5_u8BE2_u5904_u7406" class="headerlink" title="一次一个文档的查询处理"></a>一次一个文档的查询处理</h2><h2 id="u8DF3_u8DC3_u6307_u9488_u7684_u67E5_u8BE2_u5904_u7406"><a href="#u8DF3_u8DC3_u6307_u9488_u7684_u67E5_u8BE2_u5904_u7406" class="headerlink" title="跳跃指针的查询处理"></a>跳跃指针的查询处理</h2><h2 id="u77ED_u8BED_u67E5_u8BE2"><a href="#u77ED_u8BED_u67E5_u8BE2" class="headerlink" title="短语查询"></a>短语查询</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://kylin27.github.io/2016/02/06/2016.2.5.search_engine_theory/" data-id="cil3ik2s9000kh4imcl7p3xdh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/StackExchangeRecommenderSystem-repo/">StackExchangeRecommenderSystem_repo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/github/">github</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/search-engine/">search-engine</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/theory/">theory</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chord/">Chord</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DHT/">DHT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gtest/">Gtest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/">IDEA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Intellij/">Intellij</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node-js/">Node.js</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/P2P/">P2P</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/StackExchangeRecommenderSystem-repo/">StackExchangeRecommenderSystem_repo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ubuntu/">Ubuntu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cluster/">cluster</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/datastructure/">datastructure</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/debug/">debug</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/doc/">doc</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dockerfile/">dockerfile</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gtest/">gtest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java-log4j-log-pattern/">java, log4j, log pattern</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/manual/">manual</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/note/">note</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/official/">official</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/picture/">picture</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/programming-theory/">programming-theory</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/search-engine/">search-engine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/theory/">theory</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tutorial/">tutorial</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/windows/">windows</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/七牛/">七牛</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/个人简历/">个人简历</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/测试/">测试</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/翻译/">翻译</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/Chord/" style="font-size: 10px;">Chord</a> <a href="/tags/DHT/" style="font-size: 10px;">DHT</a> <a href="/tags/Gtest/" style="font-size: 10px;">Gtest</a> <a href="/tags/IDEA/" style="font-size: 10px;">IDEA</a> <a href="/tags/Intellij/" style="font-size: 10px;">Intellij</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Node-js/" style="font-size: 10px;">Node.js</a> <a href="/tags/P2P/" style="font-size: 10px;">P2P</a> <a href="/tags/StackExchangeRecommenderSystem-repo/" style="font-size: 10px;">StackExchangeRecommenderSystem_repo</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/cluster/" style="font-size: 10px;">cluster</a> <a href="/tags/datastructure/" style="font-size: 10px;">datastructure</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/doc/" style="font-size: 10px;">doc</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/dockerfile/" style="font-size: 10px;">dockerfile</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/gtest/" style="font-size: 10px;">gtest</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/java-log4j-log-pattern/" style="font-size: 10px;">java, log4j, log pattern</a> <a href="/tags/manual/" style="font-size: 10px;">manual</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/official/" style="font-size: 10px;">official</a> <a href="/tags/picture/" style="font-size: 10px;">picture</a> <a href="/tags/programming-theory/" style="font-size: 10px;">programming-theory</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a> <a href="/tags/search-engine/" style="font-size: 10px;">search-engine</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/theory/" style="font-size: 15px;">theory</a> <a href="/tags/tutorial/" style="font-size: 10px;">tutorial</a> <a href="/tags/windows/" style="font-size: 10px;">windows</a> <a href="/tags/七牛/" style="font-size: 10px;">七牛</a> <a href="/tags/个人简历/" style="font-size: 10px;">个人简历</a> <a href="/tags/测试/" style="font-size: 10px;">测试</a> <a href="/tags/翻译/" style="font-size: 10px;">翻译</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/02/26/2016.2.26.remote_debug_spark_intellij/">基于单节点的 Spark &amp; IDEA 远程调试</a>
          </li>
        
          <li>
            <a href="/2016/02/25/2016.2.25.spark.manual.translate1/">Spark 文档翻译1</a>
          </li>
        
          <li>
            <a href="/2016/02/19/2016.2.19.Google-Test 使用教程/">Google 测试框架 g-Test 使用教程</a>
          </li>
        
          <li>
            <a href="/2016/02/18/2016.2.18.dht.note/">DHT Chord 理论学习笔记 1</a>
          </li>
        
          <li>
            <a href="/2016/02/17/2016.2.17.upload_picture/">如何使用七牛存储来为你的 gihub 博客中添加图片</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Kylin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>